{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "chapter2",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qSP4cWM3Z2M7",
        "colab_type": "text"
      },
      "source": [
        "# Chapter 2: Keras in Action"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T8k3l4qx6pe-",
        "colab_type": "text"
      },
      "source": [
        "- Tensor: n-dimensional matrix\n",
        "- A single neuron will take several inputs, in here there will be a computation by actiovation function and outputing a value. Each value from several inputs will be multiplied with its corresponding weights and plug it to activation function, Voila... there is an output.\n",
        "- Activation Function:\n",
        "  - Sigmoid Activation Function\n",
        "    Defined as: $\\frac{1}{1 + e^{-z}}$ which renders the output between 0 and 1. Low influence -> low output and higher influence -> high output. Keras: keras.activations.sigmoid(x).\n",
        "  - ReLU Activation Function\n",
        "    Uses function $f(z) = max(0, z)$. Keras: keras.activations.relu(x, alpha=0.0, max_value=None). Because if the value of z is negative, the output will be zero (which is a horizontal line, with derivative zero). So the weights will not easily updated. To solve the problem, there is Leaky ReLU, where the negative value outputs a slightly slanting line instead of a horizontal line, which helps in updating the weights through backpropagation. f(z) = z, when z > 0 and f(z) = az, when z < 0 and where a is a parameter that defined as a small constant, say 0.005. Keras: keras.activations.LeakyReLU(X, alpha=0.0, max_value=None).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1scTLuqn-42P",
        "colab_type": "text"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mXFlOFVX7ln3",
        "colab_type": "text"
      },
      "source": [
        "The easiest way to define a model is by using the sequential model, which allows easy creation of a linear stack of layers. The following code: the layer would have 10 neurons, and would recieve an input with 15 neurons and be activated with the ReLU activation function.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BjTRYSI6-k9q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from keras.models import Sequential\n",
        "# from keras.layers import Dense, Activation\n",
        "\n",
        "# model = Sequential()\n",
        "# model.add(Dense(10, input_dim=15))\n",
        "# model.add(Activation('relu'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CaAbrmc6--Fh",
        "colab_type": "text"
      },
      "source": [
        "## Layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ksN0w9V_Awz",
        "colab_type": "text"
      },
      "source": [
        "- Layer in DNN is defined as a group of neurons."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hVgSiczz_WZ4",
        "colab_type": "text"
      },
      "source": [
        "### Core Layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DgqnCt_J_gwO",
        "colab_type": "text"
      },
      "source": [
        "- Dense Layer: is a regular DNN layer that connects every neuron in the defined layer to every neuron in the previous layer. For instance, if Layer 1\n",
        "has 5 neurons and Layer 2 (dense layer) has 3 neurons, the total number\n",
        "of connections between Layer 1 and Layer 2 would be 15 (5 × 3). Since it\n",
        "accommodates every possible connection between the layers, it is called a\n",
        "“dense” layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3AScMEqFABjt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "keras.layers.Dense(units, \n",
        "                   activation=None, \n",
        "                   use_bias=True,\n",
        "                   kernel_initializer='glorot_uniform',\n",
        "                   bias_initializer='zeros',\n",
        "                   kernel_regularizer=None,\n",
        "                   bias_regularizer=None,\n",
        "                   activity_regularizer=None,\n",
        "                   kernel_constraint=None,\n",
        "                   bias_constraint=None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MUFUjnqjBAI9",
        "colab_type": "text"
      },
      "source": [
        "Example: one hidden layer of 5 neurons with 10 features and single output layer (binary classification)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TK1PEhc7BIk2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model = Sequential()\n",
        "# model.add(Dense(5, input_dim=10, activation='sigmoid'))\n",
        "# model.add(Dense(1, activation='sigmoid'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-F9pFDiLBfKs",
        "colab_type": "text"
      },
      "source": [
        "## Dropout Layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGOPyU_eBh2Q",
        "colab_type": "text"
      },
      "source": [
        "Reduce overfitting by introducing regularization and generalization capabilities into the model. In action, it drops certain neurons or set it to zero and reduce computation in the training process."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEE9nPDbB-rp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# keras.layers.Dropout(rate, noise_shape=None, seed=None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6yo5mHDECXrv",
        "colab_type": "text"
      },
      "source": [
        "Add the dropout layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8Gd2tlG9CT7P",
        "colab": {}
      },
      "source": [
        "# model = Sequential()\n",
        "# model.add(Dense(5, input_dim=10, activation='sigmoid'))\n",
        "# model.add(Dropout(rate=0.1, seed=100))\n",
        "# model.add(Dense(1, activation='sigmoid'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ve5Z9O4RCwaf",
        "colab_type": "text"
      },
      "source": [
        "## Other Important Layers:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8LUz_FbJCmZP",
        "colab_type": "text"
      },
      "source": [
        "- Layerr for image feature extraction: Convolutional Layer\n",
        "- Layer for NLP: Recurrent neural network (RNN)\n",
        "- Embedding layer\n",
        "- Pooling layer\n",
        "- Merge layer\n",
        "- Normalization layer\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4SBWJmfDSZZ",
        "colab_type": "text"
      },
      "source": [
        "## The Loss Function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vmjaz0jXDV3M",
        "colab_type": "text"
      },
      "source": [
        "The error that the machine learns to minimize."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XROw5lLOErwh",
        "colab_type": "text"
      },
      "source": [
        "Some loss function for regression:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DfQidWUEEuCC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Mean Squared Error\n",
        "# keras.losses.mean_squared_error(y_actual, y_pred)\n",
        "\n",
        "# Mean Absolute Error\n",
        "# keras.losses.mean_absolute_error(y_actual, y_pred)\n",
        "\n",
        "# Mean Average Percentage Error\n",
        "# keras.losses.mean_average_percentage_error\n",
        "\n",
        "# Mean Square Logarithmic Error\n",
        "# keras.losses.mean_square_logarithmic_error"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i01iZuXbFihB",
        "colab_type": "text"
      },
      "source": [
        "Some loss function for classification:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xsgavJlqFpQk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Binary cross-entropy: Defines the loss when the\n",
        "# categorical outcomes is a binary variable, that is, with\n",
        "# two possible outcomes: (Pass/Fail) or (Yes/No)\n",
        "# keras.losses.cross_binaryentropy(y_actual, y_pred)\n",
        "\n",
        "# Categorical cross-entropy: Defines the loss when the\n",
        "# categorical outcomes is a nonbinary, that is, >2 possible\n",
        "# outcomes: (Yes/No/Maybe) or (Type 1/ Type 2/… Type n)\n",
        "# keras.losses.categorical_crossentropy(y_actual, y_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JB5bQuzqGM2c",
        "colab_type": "text"
      },
      "source": [
        "## Optimizers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYDVhKAqGSx0",
        "colab_type": "text"
      },
      "source": [
        "- Giving feedback to the model.\n",
        "- Backpropagation is an optimizer algorithm.\n",
        "- Random weights at the beginning. \n",
        "- The weights that determined the\n",
        "influence of a neuron on the next neuron or the final output are updated\n",
        "during the learning process by the network.\n",
        "- The computation of one training sample from the input layer\n",
        "to the output layer is called a pass.\n",
        "- A batch is a collection\n",
        "of training samples from the entire input.\n",
        "- The computing of all training samples provided in the input data\n",
        "with batch-by-batch weight updates is called an epoch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yKwzmEh34iM5",
        "colab_type": "text"
      },
      "source": [
        "### Stochastic Gradient Descent (SGD)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5iIZvrMx627V",
        "colab_type": "text"
      },
      "source": [
        "- Performs an iteration with each training sample (after the pass of each training sample it calculates the loss and updates the weight)\n",
        "- Weights = Weights - learning rate * loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8P1zF8b97SYQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# keras.optimizers.SGD(lr=0.01, momentum=0.0, decay=0.0, nesterov=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zARPutR07cHl",
        "colab_type": "text"
      },
      "source": [
        "- To reduce the fluctuations, reduce the number of iterations by providing mini batch. Usually in powers of 2 (4, 8, 16, ..)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NHWNH6-37zFy",
        "colab_type": "text"
      },
      "source": [
        "### Adam"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NP5QeBVf71sM",
        "colab_type": "text"
      },
      "source": [
        "- Adaptive Moment Estimation\n",
        "- COmputes an adaptive learning rate for each parameter.\n",
        "- It defines momentum and variance of the gradient of the loss\n",
        "and leverages a combined effect to update the weight parameters. The\n",
        "momentum and variance together help smooth the learning curve and\n",
        "effectively improve the learning process.\n",
        "- Weights = Weights - (momentum + variance)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BTSzOlMz8T-U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999,\n",
        "# epsilon=None, decay=0.0, amsgrad=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F0CmuvZC8fZi",
        "colab_type": "text"
      },
      "source": [
        "The parameters beta_1 and beta_2 are used in computing the momentum and variance respectively."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfoWBb5P8tem",
        "colab_type": "text"
      },
      "source": [
        "### Other Important Optimizers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82QvZk4881V0",
        "colab_type": "text"
      },
      "source": [
        "- Adagrad\n",
        "- Adadelta\n",
        "- RMSProp\n",
        "- Adamax\n",
        "- Nadam"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JrBTmFb29JHr",
        "colab_type": "text"
      },
      "source": [
        "## Metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z8Y7bx2B9K21",
        "colab_type": "text"
      },
      "source": [
        "- Function used to judge the performance of the model on a different unseen dataset (validation set).\n",
        "- Difference to loss function is that the results from metrics are not used in training teh model with respect to optimization.\n",
        "- Used to validate the test results while reporting.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ozfLI_k_9lYG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Binary accuracy\n",
        "# keras.metrics.binary_accuracy\n",
        "\n",
        "# Categorical accuracy\n",
        "# keras.metrics.categorical_accuracy\n",
        "\n",
        "# Sparse categorical accuracy\n",
        "# keras.metrics.sparse_categorical_accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZpjupTlI9_Jj",
        "colab_type": "text"
      },
      "source": [
        "## Model Configuration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HGJBw-_5-Ln4",
        "colab_type": "text"
      },
      "source": [
        "Once you have designed your network, Keras provides you with an\n",
        "easy one-step model configuration process with the ‘compile’ command.\n",
        "To compile a model, we need to provide three parameters: an optimization\n",
        "function, a loss function, and a metric for the model to measure\n",
        "performance on the validation dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KA3PvBk6-dPp",
        "colab_type": "text"
      },
      "source": [
        "The following example builds a DNN with two hidden layers, with\n",
        "32 and 16 neurons, respectively, with a ReLU activation function. The\n",
        "final output is for a binary categorical numeric output using a sigmoid\n",
        "activation. We compile the model with the Adam optimizer and define\n",
        "binary cross-entropy as the loss function and “accuracy” as the metric for\n",
        "validation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X4v6ieHc-sTS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from keras.models import Sequential\n",
        "# from keras.layers import Dense, Activation\n",
        "\n",
        "# model = Sequential()\n",
        "# model.add(Dense(32, input_dim=10, activation='relu')) \n",
        "# # first layer 32 neurons and 10 input features\n",
        "# model.add(Dense(16, activation='relu')\n",
        "# # second layer 16 neurons\n",
        "# model.add(Dese(1, activation='sigmoid'))\n",
        "# # output layer, binary classification\n",
        "\n",
        "# model.compile(optimizer='Adam', loss='binary_crossentropy', \n",
        "#               metrics='accuracy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NuMlVm0L_nWP",
        "colab_type": "text"
      },
      "source": [
        "## Model Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7tKH4ANZ_p80",
        "colab_type": "text"
      },
      "source": [
        "- While training, it is always a good practice to provide a validation dataset for us to evaluate whether the model is performing as desired after each epoch.\n",
        "- The performance on the validation dataset is a good cue for the overall performance.\n",
        "- Common practice: 60% for training, 20% for validation, and 20% for testing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Kp5x0grBPEP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# if we already have the model defined\n",
        "# model.fit(X_train, y_train, batch_size=64, epoch=3, validation_data=(X_val, y_val))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZ47YG_QBbCZ",
        "colab_type": "text"
      },
      "source": [
        "We have a model being trained on a training dataset named x_train with\n",
        "the actual labels in y_train. We choose a batch size of 64. Therefore, if there\n",
        "were 500 training samples, the model would intake and process 64 samples\n",
        "at a time in a batch before it updates the model weights. The last batch may\n",
        "have < 64 training sample if unavailable. We have set the number of epochs\n",
        "to three; therefore, the whole process of training 500 sample in batches of 64\n",
        "will be repeated thrice. Also, we have provided the validation dataset as x_val\n",
        "and y_val. At the end of each epoch, the model would use the validation data\n",
        "to make predictions and compute the performance metrics as defined in the\n",
        "metrics parameter of the model configuration."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FBYA5d0MCLf5",
        "colab_type": "code",
        "outputId": "729a6943-a84b-49c3-a912-f21112f987b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 499
        }
      },
      "source": [
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation\n",
        "\n",
        "# generate dummy training dataset\n",
        "np.random.seed(2019)\n",
        "x_train = np.random.random((6000, 10))\n",
        "y_train = np.random.randint(2, size=(6000, 1))\n",
        "\n",
        "# generate dummy validation dataset\n",
        "x_val = np.random.random((2000, 10))\n",
        "y_val = np.random.randint(2, size=(2000, 1))\n",
        "\n",
        "# generate dummy test dataset\n",
        "x_test = np.random.random((2000, 10))\n",
        "y_test = np.random.randint(2, size=(2000, 1))\n",
        "\n",
        "\n",
        "# define the model architecture\n",
        "model = Sequential()\n",
        "model.add(Dense(64, input_dim=10, activation='relu')) # layer 1\n",
        "model.add(Dense(32, activation='relu')) # layer 2\n",
        "model.add(Dense(16, activation='relu')) # layer 3\n",
        "model.add(Dense(8, activation='relu')) # layer 4\n",
        "model.add(Dense(4, activation='relu')) # layer 5\n",
        "model.add(Dense(1, activation='sigmoid')) # output layer\n",
        "\n",
        "#configure the model\n",
        "model.compile(optimizer='Adam', loss='binary_crossentropy', \n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# train the model\n",
        "model.fit(x_train, y_train, batch_size=64, epochs=3, \n",
        "          validation_data=(x_val, y_val))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0904 06:56:20.203682 140383334332288 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0904 06:56:20.243904 140383334332288 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0904 06:56:20.249902 140383334332288 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0904 06:56:20.334862 140383334332288 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0904 06:56:20.357499 140383334332288 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "W0904 06:56:20.365105 140383334332288 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0904 06:56:20.599663 140383334332288 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 6000 samples, validate on 2000 samples\n",
            "Epoch 1/3\n",
            "6000/6000 [==============================] - 1s 165us/step - loss: 0.6933 - acc: 0.4913 - val_loss: 0.6932 - val_acc: 0.4965\n",
            "Epoch 2/3\n",
            "6000/6000 [==============================] - 0s 28us/step - loss: 0.6931 - acc: 0.5098 - val_loss: 0.6933 - val_acc: 0.4935\n",
            "Epoch 3/3\n",
            "6000/6000 [==============================] - 0s 28us/step - loss: 0.6930 - acc: 0.5098 - val_loss: 0.6933 - val_acc: 0.4935\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fad50d98240>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6OClLH8D2NO",
        "colab_type": "text"
      },
      "source": [
        "## Model Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NWodjvhfEdgQ",
        "colab_type": "text"
      },
      "source": [
        "- Understanding how effectively your model is performing on an unseen test dataset.\n",
        "- Keras provides the model object equipped with inbuilt model\n",
        "evaluation and another function to predict the outcome from a test\n",
        "dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "slAwrdjBE9b7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# evaluate(x=None, y=None, batch_size=None, verbose=1, \n",
        "#          sample_weight=None, steps=None)    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDJF7CL0FFNs",
        "colab_type": "code",
        "outputId": "9c28aa09-82a1-4eed-c23f-dc2e454e6b63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "print(model.evaluate(x_test, y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2000/2000 [==============================] - 0s 23us/step\n",
            "[0.6932605152130127, 0.494]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_E2GIcauFk2n",
        "colab_type": "code",
        "outputId": "c48493de-b6ca-4c02-a87e-8c996ab1aef7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(model.metrics_names)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['loss', 'acc']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "INJ99wIIF6IH",
        "colab_type": "code",
        "outputId": "63340ac7-1c8b-401a-e814-0d00455f604f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "# make predictions on the test dataset and print the first 10 predictions\n",
        "pred = model.predict(x_test)\n",
        "pred[:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.49437454],\n",
              "       [0.49437454],\n",
              "       [0.49437454],\n",
              "       [0.49437454],\n",
              "       [0.49437454],\n",
              "       [0.49437454],\n",
              "       [0.49437454],\n",
              "       [0.49437454],\n",
              "       [0.49437454],\n",
              "       [0.49437454]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDSCpnoJGP_y",
        "colab_type": "text"
      },
      "source": [
        "This output can be used to make even more refined final predictions.\n",
        "A simple example is that the model would use 0.5 as the threshold for the\n",
        "predictions. Therefore, any predicted value above 0.5 is classified as 1 (say,\n",
        "Pass), and others as 0 (Fail)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z77F1QuKGf3C",
        "colab_type": "text"
      },
      "source": [
        "## Putting All the Building Blocks Together"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QdS64tIYGpT1",
        "colab_type": "code",
        "outputId": "f6c7a9f2-98a5-4645-fac0-86763f6f9023",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        }
      },
      "source": [
        "# download the data using keras\n",
        "from keras.datasets import boston_housing\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = boston_housing.load_data()\n",
        "\n",
        "#Explore the data structure using basic python commands\n",
        "print(\"Type of the Dataset:\",type(y_train))\n",
        "print(\"Shape of training data :\",x_train.shape)\n",
        "print(\"Shape of training labels :\",y_train.shape)\n",
        "print(\"Shape of testing data :\",type(x_test))\n",
        "print(\"Shape of testing labels :\",y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/keras-datasets/boston_housing.npz\n",
            "57344/57026 [==============================] - 0s 0us/step\n",
            "Type of the Dataset: <class 'numpy.ndarray'>\n",
            "Shape of training data : (404, 13)\n",
            "Shape of training labels : (404,)\n",
            "Shape of testing data : <class 'numpy.ndarray'>\n",
            "Shape of testing labels : (102,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YLOfUU6gHQd6",
        "colab_type": "code",
        "outputId": "717bf8df-97ea-4b38-ebed-ed044d647e29",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        }
      },
      "source": [
        "x_train[:3, :]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.23247e+00, 0.00000e+00, 8.14000e+00, 0.00000e+00, 5.38000e-01,\n",
              "        6.14200e+00, 9.17000e+01, 3.97690e+00, 4.00000e+00, 3.07000e+02,\n",
              "        2.10000e+01, 3.96900e+02, 1.87200e+01],\n",
              "       [2.17700e-02, 8.25000e+01, 2.03000e+00, 0.00000e+00, 4.15000e-01,\n",
              "        7.61000e+00, 1.57000e+01, 6.27000e+00, 2.00000e+00, 3.48000e+02,\n",
              "        1.47000e+01, 3.95380e+02, 3.11000e+00],\n",
              "       [4.89822e+00, 0.00000e+00, 1.81000e+01, 0.00000e+00, 6.31000e-01,\n",
              "        4.97000e+00, 1.00000e+02, 1.33250e+00, 2.40000e+01, 6.66000e+02,\n",
              "        2.02000e+01, 3.75520e+02, 3.26000e+00]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kgXvmrSKHtbM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# extract the last 100 rows from the training data to create the validation datasets\n",
        "x_val = x_train[300:,]\n",
        "y_val = y_train[300:,]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENXNV5X6IOEi",
        "colab_type": "code",
        "outputId": "50f59821-6607-4d54-a93b-e580e21f87f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "# define the model architecture\n",
        "model = Sequential()\n",
        "model.add(Dense(13, input_dim=13, kernel_initializer='normal', \n",
        "                activation='relu'))\n",
        "model.add(Dense(6, kernel_initializer='normal', activation='relu'))\n",
        "model.add(Dense(1, kernel_initializer='normal'))\n",
        "\n",
        "# compile model\n",
        "model.compile(loss='mean_squared_error', optimizer='adam', \n",
        "              metrics=['mean_absolute_percentage_error'])\n",
        "\n",
        "# train the model\n",
        "model.fit(x_train, y_train, batch_size=32, epochs=3,\n",
        "          validation_data=(x_val, y_val))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 404 samples, validate on 104 samples\n",
            "Epoch 1/3\n",
            "404/404 [==============================] - 0s 591us/step - loss: 571.4900 - mean_absolute_percentage_error: 98.0360 - val_loss: 641.2723 - val_mean_absolute_percentage_error: 95.5404\n",
            "Epoch 2/3\n",
            "404/404 [==============================] - 0s 54us/step - loss: 535.8000 - mean_absolute_percentage_error: 93.3394 - val_loss: 607.5268 - val_mean_absolute_percentage_error: 91.8053\n",
            "Epoch 3/3\n",
            "404/404 [==============================] - 0s 50us/step - loss: 501.1250 - mean_absolute_percentage_error: 88.6046 - val_loss: 562.5906 - val_mean_absolute_percentage_error: 86.5415\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fad4b9625c0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HMuvoHnKJdVs",
        "colab_type": "code",
        "outputId": "08fddc71-47f1-41bc-8f06-9fa47f4913bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "results = model.evaluate(x_test, y_test)\n",
        "\n",
        "for i in range(len(model.metrics_names)):\n",
        "  print(model.metrics_names[i], ' : ', results[i])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "102/102 [==============================] - 0s 66us/step\n",
            "loss  :  502.7818053002451\n",
            "mean_absolute_percentage_error  :  84.62569517247817\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIpt0vXFKFuy",
        "colab_type": "code",
        "outputId": "020cb932-0943-4e98-c861-efdae2bc4b0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "results"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[502.7818053002451, 84.62569517247817]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5dvPGn3UKHrj",
        "colab_type": "code",
        "outputId": "9da63e53-de36-4d4e-b086-7f5254da5e54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "model.metrics_names"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['loss', 'mean_absolute_percentage_error']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHOLQNC7KLGV",
        "colab_type": "text"
      },
      "source": [
        "In DL, the model updates weight after every iteration and evaluates\n",
        "after every epoch. Since the updates are quite small, it usually takes a fairly\n",
        "higher number of epochs for a generic model to learn appropriately. To\n",
        "test the performance once again, let’s increase the number of epochs to 30\n",
        "instead of 3. This would increase the computation significantly and might\n",
        "take a while to execute. But since this is a fairly small dataset, training with\n",
        "30 epochs should not be a problem. It should execute in ~1 min on your\n",
        "system."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wWPPy3z_Kij3",
        "colab_type": "code",
        "outputId": "7597bfc5-05ae-4183-a797-21a7be110960",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# train the model\n",
        "model.fit(x_train, y_train, batch_size=32, epochs=30, \n",
        "          validation_data=(x_val,y_val))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 404 samples, validate on 104 samples\n",
            "Epoch 1/30\n",
            "404/404 [==============================] - 0s 69us/step - loss: 453.5345 - mean_absolute_percentage_error: 81.8421 - val_loss: 501.0008 - val_mean_absolute_percentage_error: 78.7989\n",
            "Epoch 2/30\n",
            "404/404 [==============================] - 0s 55us/step - loss: 390.5902 - mean_absolute_percentage_error: 72.2927 - val_loss: 420.7652 - val_mean_absolute_percentage_error: 67.7351\n",
            "Epoch 3/30\n",
            "404/404 [==============================] - 0s 52us/step - loss: 312.7396 - mean_absolute_percentage_error: 60.1281 - val_loss: 327.0805 - val_mean_absolute_percentage_error: 54.5708\n",
            "Epoch 4/30\n",
            "404/404 [==============================] - 0s 63us/step - loss: 231.3733 - mean_absolute_percentage_error: 49.7813 - val_loss: 236.2581 - val_mean_absolute_percentage_error: 43.8246\n",
            "Epoch 5/30\n",
            "404/404 [==============================] - 0s 52us/step - loss: 164.9147 - mean_absolute_percentage_error: 43.2696 - val_loss: 173.8517 - val_mean_absolute_percentage_error: 39.1474\n",
            "Epoch 6/30\n",
            "404/404 [==============================] - 0s 62us/step - loss: 133.1797 - mean_absolute_percentage_error: 43.5181 - val_loss: 148.2291 - val_mean_absolute_percentage_error: 40.2075\n",
            "Epoch 7/30\n",
            "404/404 [==============================] - 0s 49us/step - loss: 126.1723 - mean_absolute_percentage_error: 45.6834 - val_loss: 141.1005 - val_mean_absolute_percentage_error: 40.7164\n",
            "Epoch 8/30\n",
            "404/404 [==============================] - 0s 60us/step - loss: 122.2136 - mean_absolute_percentage_error: 45.2284 - val_loss: 137.1575 - val_mean_absolute_percentage_error: 39.4406\n",
            "Epoch 9/30\n",
            "404/404 [==============================] - 0s 61us/step - loss: 117.2418 - mean_absolute_percentage_error: 43.2036 - val_loss: 134.4291 - val_mean_absolute_percentage_error: 37.8270\n",
            "Epoch 10/30\n",
            "404/404 [==============================] - 0s 56us/step - loss: 112.9129 - mean_absolute_percentage_error: 41.5279 - val_loss: 130.5278 - val_mean_absolute_percentage_error: 36.8225\n",
            "Epoch 11/30\n",
            "404/404 [==============================] - 0s 48us/step - loss: 108.6756 - mean_absolute_percentage_error: 40.3725 - val_loss: 126.3823 - val_mean_absolute_percentage_error: 35.8421\n",
            "Epoch 12/30\n",
            "404/404 [==============================] - 0s 62us/step - loss: 104.6997 - mean_absolute_percentage_error: 39.6706 - val_loss: 121.1597 - val_mean_absolute_percentage_error: 35.3442\n",
            "Epoch 13/30\n",
            "404/404 [==============================] - 0s 48us/step - loss: 100.2692 - mean_absolute_percentage_error: 38.0518 - val_loss: 118.4958 - val_mean_absolute_percentage_error: 33.8662\n",
            "Epoch 14/30\n",
            "404/404 [==============================] - 0s 50us/step - loss: 96.0498 - mean_absolute_percentage_error: 36.9076 - val_loss: 113.9000 - val_mean_absolute_percentage_error: 33.3449\n",
            "Epoch 15/30\n",
            "404/404 [==============================] - 0s 62us/step - loss: 92.3126 - mean_absolute_percentage_error: 36.4821 - val_loss: 109.1431 - val_mean_absolute_percentage_error: 33.1206\n",
            "Epoch 16/30\n",
            "404/404 [==============================] - 0s 53us/step - loss: 88.0548 - mean_absolute_percentage_error: 35.2348 - val_loss: 106.3866 - val_mean_absolute_percentage_error: 31.7820\n",
            "Epoch 17/30\n",
            "404/404 [==============================] - 0s 55us/step - loss: 84.5579 - mean_absolute_percentage_error: 33.6222 - val_loss: 103.5307 - val_mean_absolute_percentage_error: 30.7114\n",
            "Epoch 18/30\n",
            "404/404 [==============================] - 0s 53us/step - loss: 81.2203 - mean_absolute_percentage_error: 32.9339 - val_loss: 99.3997 - val_mean_absolute_percentage_error: 30.3387\n",
            "Epoch 19/30\n",
            "404/404 [==============================] - 0s 57us/step - loss: 78.0676 - mean_absolute_percentage_error: 32.3096 - val_loss: 96.6814 - val_mean_absolute_percentage_error: 29.4608\n",
            "Epoch 20/30\n",
            "404/404 [==============================] - 0s 53us/step - loss: 75.2576 - mean_absolute_percentage_error: 31.3226 - val_loss: 94.4383 - val_mean_absolute_percentage_error: 28.5707\n",
            "Epoch 21/30\n",
            "404/404 [==============================] - 0s 57us/step - loss: 72.8589 - mean_absolute_percentage_error: 30.8109 - val_loss: 91.7662 - val_mean_absolute_percentage_error: 28.1621\n",
            "Epoch 22/30\n",
            "404/404 [==============================] - 0s 66us/step - loss: 70.4709 - mean_absolute_percentage_error: 29.9006 - val_loss: 90.5910 - val_mean_absolute_percentage_error: 27.1183\n",
            "Epoch 23/30\n",
            "404/404 [==============================] - 0s 67us/step - loss: 68.5022 - mean_absolute_percentage_error: 29.0861 - val_loss: 88.8413 - val_mean_absolute_percentage_error: 26.5944\n",
            "Epoch 24/30\n",
            "404/404 [==============================] - 0s 55us/step - loss: 66.8177 - mean_absolute_percentage_error: 28.9826 - val_loss: 86.7833 - val_mean_absolute_percentage_error: 26.4609\n",
            "Epoch 25/30\n",
            "404/404 [==============================] - 0s 57us/step - loss: 65.2836 - mean_absolute_percentage_error: 28.4413 - val_loss: 86.2945 - val_mean_absolute_percentage_error: 25.4565\n",
            "Epoch 26/30\n",
            "404/404 [==============================] - 0s 54us/step - loss: 64.1019 - mean_absolute_percentage_error: 27.6211 - val_loss: 85.5351 - val_mean_absolute_percentage_error: 24.8971\n",
            "Epoch 27/30\n",
            "404/404 [==============================] - 0s 58us/step - loss: 63.2510 - mean_absolute_percentage_error: 27.0462 - val_loss: 84.5742 - val_mean_absolute_percentage_error: 24.7239\n",
            "Epoch 28/30\n",
            "404/404 [==============================] - 0s 58us/step - loss: 62.3758 - mean_absolute_percentage_error: 27.3603 - val_loss: 83.6432 - val_mean_absolute_percentage_error: 24.6530\n",
            "Epoch 29/30\n",
            "404/404 [==============================] - 0s 55us/step - loss: 61.9036 - mean_absolute_percentage_error: 26.4552 - val_loss: 84.1389 - val_mean_absolute_percentage_error: 23.8251\n",
            "Epoch 30/30\n",
            "404/404 [==============================] - 0s 54us/step - loss: 61.1106 - mean_absolute_percentage_error: 26.6385 - val_loss: 82.4532 - val_mean_absolute_percentage_error: 24.4813\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fad4b416390>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MRBsvXHdK2mV",
        "colab_type": "code",
        "outputId": "8176305e-31ff-41e3-e858-f2b53b17adc4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "results = model.evaluate(x_test, y_test)\n",
        "\n",
        "for i in range(len(model.metrics_names)):\n",
        "  print(model.metrics_names[i], ' : ', results[i])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "102/102 [==============================] - 0s 179us/step\n",
            "loss  :  67.16364034016927\n",
            "mean_absolute_percentage_error  :  32.16827949823118\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o4EDIKvJLhar",
        "colab_type": "text"
      },
      "source": [
        "As discussed earlier, this gap is an indicator that the\n",
        "model has overfit, or in simple terms, has overcomplicated the process of\n",
        "learning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Sctodj-L9Lt",
        "colab_type": "text"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PHazypexMMTg",
        "colab_type": "text"
      },
      "source": [
        "## Experimentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1yqxIfpyMOOa",
        "colab_type": "code",
        "outputId": "02ea27cd-bca4-493d-bf54-e31889b94e8c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# import the tools\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation\n",
        "\n",
        "# download the dataset\n",
        "(x_train, y_train), (x_test, y_test) = boston_housing.load_data()\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "# make validation data\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.15, random_state=21)\n",
        "\n",
        "# define the model\n",
        "model = Sequential()\n",
        "model.add(Dense(13, input_dim=13, activation='relu'))\n",
        "model.add(Dense(11, activation='relu'))\n",
        "model.add(Dense(7, activation='relu'))\n",
        "model.add(Dense(3, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# compile the model\n",
        "model.compile(optimizer='Adam', loss='mean_squared_error', metrics=['mean_absolute_error'])\n",
        "\n",
        "# train the model\n",
        "model.fit(x_train, y_train, batch_size=50, epochs=50, validation_data=(x_val, y_val))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 343 samples, validate on 61 samples\n",
            "Epoch 1/50\n",
            "343/343 [==============================] - 0s 1ms/step - loss: 545.2617 - mean_absolute_error: 21.4563 - val_loss: 526.1126 - val_mean_absolute_error: 21.0508\n",
            "Epoch 2/50\n",
            "343/343 [==============================] - 0s 44us/step - loss: 545.2617 - mean_absolute_error: 21.4563 - val_loss: 526.1126 - val_mean_absolute_error: 21.0508\n",
            "Epoch 3/50\n",
            "343/343 [==============================] - 0s 44us/step - loss: 545.2617 - mean_absolute_error: 21.4563 - val_loss: 526.1126 - val_mean_absolute_error: 21.0508\n",
            "Epoch 4/50\n",
            "343/343 [==============================] - 0s 44us/step - loss: 545.2617 - mean_absolute_error: 21.4563 - val_loss: 526.1126 - val_mean_absolute_error: 21.0508\n",
            "Epoch 5/50\n",
            "343/343 [==============================] - 0s 45us/step - loss: 545.2617 - mean_absolute_error: 21.4563 - val_loss: 526.1126 - val_mean_absolute_error: 21.0508\n",
            "Epoch 6/50\n",
            "343/343 [==============================] - 0s 46us/step - loss: 545.2617 - mean_absolute_error: 21.4563 - val_loss: 526.1126 - val_mean_absolute_error: 21.0508\n",
            "Epoch 7/50\n",
            "343/343 [==============================] - 0s 44us/step - loss: 545.2617 - mean_absolute_error: 21.4563 - val_loss: 526.1126 - val_mean_absolute_error: 21.0508\n",
            "Epoch 8/50\n",
            "343/343 [==============================] - 0s 56us/step - loss: 545.2617 - mean_absolute_error: 21.4563 - val_loss: 526.1126 - val_mean_absolute_error: 21.0508\n",
            "Epoch 9/50\n",
            "343/343 [==============================] - 0s 46us/step - loss: 545.2617 - mean_absolute_error: 21.4563 - val_loss: 526.1126 - val_mean_absolute_error: 21.0508\n",
            "Epoch 10/50\n",
            "343/343 [==============================] - 0s 40us/step - loss: 545.2617 - mean_absolute_error: 21.4563 - val_loss: 526.1126 - val_mean_absolute_error: 21.0508\n",
            "Epoch 11/50\n",
            "343/343 [==============================] - 0s 44us/step - loss: 545.2617 - mean_absolute_error: 21.4563 - val_loss: 526.1126 - val_mean_absolute_error: 21.0508\n",
            "Epoch 12/50\n",
            "343/343 [==============================] - 0s 52us/step - loss: 545.2617 - mean_absolute_error: 21.4563 - val_loss: 526.1126 - val_mean_absolute_error: 21.0508\n",
            "Epoch 13/50\n",
            "343/343 [==============================] - 0s 51us/step - loss: 545.2617 - mean_absolute_error: 21.4563 - val_loss: 526.1126 - val_mean_absolute_error: 21.0508\n",
            "Epoch 14/50\n",
            "343/343 [==============================] - 0s 59us/step - loss: 545.2617 - mean_absolute_error: 21.4563 - val_loss: 526.1126 - val_mean_absolute_error: 21.0508\n",
            "Epoch 15/50\n",
            "343/343 [==============================] - 0s 45us/step - loss: 545.2617 - mean_absolute_error: 21.4563 - val_loss: 526.1126 - val_mean_absolute_error: 21.0508\n",
            "Epoch 16/50\n",
            "343/343 [==============================] - 0s 40us/step - loss: 545.2617 - mean_absolute_error: 21.4563 - val_loss: 526.1126 - val_mean_absolute_error: 21.0508\n",
            "Epoch 17/50\n",
            "343/343 [==============================] - 0s 44us/step - loss: 545.2618 - mean_absolute_error: 21.4563 - val_loss: 526.1126 - val_mean_absolute_error: 21.0508\n",
            "Epoch 18/50\n",
            "343/343 [==============================] - 0s 50us/step - loss: 545.2617 - mean_absolute_error: 21.4563 - val_loss: 526.1126 - val_mean_absolute_error: 21.0508\n",
            "Epoch 19/50\n",
            "343/343 [==============================] - 0s 51us/step - loss: 545.2617 - mean_absolute_error: 21.4563 - val_loss: 526.1126 - val_mean_absolute_error: 21.0508\n",
            "Epoch 20/50\n",
            "343/343 [==============================] - 0s 41us/step - loss: 545.2617 - mean_absolute_error: 21.4563 - val_loss: 526.1126 - val_mean_absolute_error: 21.0508\n",
            "Epoch 21/50\n",
            "343/343 [==============================] - 0s 39us/step - loss: 545.2617 - mean_absolute_error: 21.4563 - val_loss: 526.1126 - val_mean_absolute_error: 21.0508\n",
            "Epoch 22/50\n",
            "343/343 [==============================] - 0s 44us/step - loss: 545.2617 - mean_absolute_error: 21.4563 - val_loss: 526.1126 - val_mean_absolute_error: 21.0508\n",
            "Epoch 23/50\n",
            "343/343 [==============================] - 0s 45us/step - loss: 545.2617 - mean_absolute_error: 21.4563 - val_loss: 526.1126 - val_mean_absolute_error: 21.0508\n",
            "Epoch 24/50\n",
            "343/343 [==============================] - 0s 52us/step - loss: 545.2617 - mean_absolute_error: 21.4563 - val_loss: 526.1126 - val_mean_absolute_error: 21.0508\n",
            "Epoch 25/50\n",
            "343/343 [==============================] - 0s 54us/step - loss: 545.2617 - mean_absolute_error: 21.4563 - val_loss: 526.1126 - val_mean_absolute_error: 21.0508\n",
            "Epoch 26/50\n",
            "343/343 [==============================] - 0s 48us/step - loss: 545.2617 - mean_absolute_error: 21.4563 - val_loss: 526.1126 - val_mean_absolute_error: 21.0508\n",
            "Epoch 27/50\n",
            "343/343 [==============================] - 0s 44us/step - loss: 545.2617 - mean_absolute_error: 21.4563 - val_loss: 526.1126 - val_mean_absolute_error: 21.0508\n",
            "Epoch 28/50\n",
            "343/343 [==============================] - 0s 48us/step - loss: 545.2617 - mean_absolute_error: 21.4563 - val_loss: 526.1126 - val_mean_absolute_error: 21.0508\n",
            "Epoch 29/50\n",
            "343/343 [==============================] - 0s 48us/step - loss: 545.2617 - mean_absolute_error: 21.4563 - val_loss: 526.1126 - val_mean_absolute_error: 21.0508\n",
            "Epoch 30/50\n",
            "343/343 [==============================] - 0s 58us/step - loss: 545.2617 - mean_absolute_error: 21.4563 - val_loss: 526.1126 - val_mean_absolute_error: 21.0508\n",
            "Epoch 31/50\n",
            "343/343 [==============================] - 0s 46us/step - loss: 545.2617 - mean_absolute_error: 21.4563 - val_loss: 526.1126 - val_mean_absolute_error: 21.0508\n",
            "Epoch 32/50\n",
            "343/343 [==============================] - 0s 47us/step - loss: 545.2617 - mean_absolute_error: 21.4563 - val_loss: 526.1126 - val_mean_absolute_error: 21.0508\n",
            "Epoch 33/50\n",
            "343/343 [==============================] - 0s 49us/step - loss: 545.2617 - mean_absolute_error: 21.4563 - val_loss: 526.1126 - val_mean_absolute_error: 21.0508\n",
            "Epoch 34/50\n",
            "343/343 [==============================] - 0s 41us/step - loss: 545.2617 - mean_absolute_error: 21.4563 - val_loss: 526.1126 - val_mean_absolute_error: 21.0508\n",
            "Epoch 35/50\n",
            "343/343 [==============================] - 0s 44us/step - loss: 545.2618 - mean_absolute_error: 21.4563 - val_loss: 526.1126 - val_mean_absolute_error: 21.0508\n",
            "Epoch 36/50\n",
            "343/343 [==============================] - 0s 53us/step - loss: 545.2617 - mean_absolute_error: 21.4563 - val_loss: 526.1126 - val_mean_absolute_error: 21.0508\n",
            "Epoch 37/50\n",
            "343/343 [==============================] - 0s 50us/step - loss: 545.2617 - mean_absolute_error: 21.4563 - val_loss: 526.1126 - val_mean_absolute_error: 21.0508\n",
            "Epoch 38/50\n",
            "343/343 [==============================] - 0s 43us/step - loss: 545.2617 - mean_absolute_error: 21.4563 - val_loss: 526.1126 - val_mean_absolute_error: 21.0508\n",
            "Epoch 39/50\n",
            "343/343 [==============================] - 0s 41us/step - loss: 545.2617 - mean_absolute_error: 21.4563 - val_loss: 526.1126 - val_mean_absolute_error: 21.0508\n",
            "Epoch 40/50\n",
            "343/343 [==============================] - 0s 45us/step - loss: 545.2617 - mean_absolute_error: 21.4563 - val_loss: 526.1126 - val_mean_absolute_error: 21.0508\n",
            "Epoch 41/50\n",
            "343/343 [==============================] - 0s 46us/step - loss: 545.2617 - mean_absolute_error: 21.4563 - val_loss: 526.1126 - val_mean_absolute_error: 21.0508\n",
            "Epoch 42/50\n",
            "343/343 [==============================] - 0s 42us/step - loss: 545.2617 - mean_absolute_error: 21.4563 - val_loss: 526.1126 - val_mean_absolute_error: 21.0508\n",
            "Epoch 43/50\n",
            "343/343 [==============================] - 0s 48us/step - loss: 545.2617 - mean_absolute_error: 21.4563 - val_loss: 526.1126 - val_mean_absolute_error: 21.0508\n",
            "Epoch 44/50\n",
            "343/343 [==============================] - 0s 55us/step - loss: 545.2617 - mean_absolute_error: 21.4563 - val_loss: 526.1126 - val_mean_absolute_error: 21.0508\n",
            "Epoch 45/50\n",
            "343/343 [==============================] - 0s 51us/step - loss: 545.2617 - mean_absolute_error: 21.4563 - val_loss: 526.1126 - val_mean_absolute_error: 21.0508\n",
            "Epoch 46/50\n",
            "343/343 [==============================] - 0s 50us/step - loss: 545.2617 - mean_absolute_error: 21.4563 - val_loss: 526.1126 - val_mean_absolute_error: 21.0508\n",
            "Epoch 47/50\n",
            "343/343 [==============================] - 0s 44us/step - loss: 545.2617 - mean_absolute_error: 21.4563 - val_loss: 526.1126 - val_mean_absolute_error: 21.0508\n",
            "Epoch 48/50\n",
            "343/343 [==============================] - 0s 53us/step - loss: 545.2617 - mean_absolute_error: 21.4563 - val_loss: 526.1126 - val_mean_absolute_error: 21.0508\n",
            "Epoch 49/50\n",
            "343/343 [==============================] - 0s 47us/step - loss: 545.2617 - mean_absolute_error: 21.4563 - val_loss: 526.1126 - val_mean_absolute_error: 21.0508\n",
            "Epoch 50/50\n",
            "343/343 [==============================] - 0s 44us/step - loss: 545.2617 - mean_absolute_error: 21.4563 - val_loss: 526.1126 - val_mean_absolute_error: 21.0508\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fad429c4b38>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GIU5W-gFPmR4",
        "colab_type": "code",
        "outputId": "cb835fcb-0f93-44d6-ca0e-ec683c6b1c8c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "results = model.evaluate(x_test, y_test)\n",
        "print(results)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "102/102 [==============================] - 0s 147us/step\n",
            "[570.7010079178156, 22.078431858735925]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}