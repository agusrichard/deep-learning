{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"deeplearning-with-keras-chapter2.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"U06oRfPuSUpm","colab_type":"text"},"source":["# Chapter 2: Keras Installation and API"]},{"cell_type":"markdown","metadata":{"id":"CBoyYbFIlkJa","colab_type":"text"},"source":["## Getting Started with Keras Architecture"]},{"cell_type":"markdown","metadata":{"id":"fbr5pO-nls8-","colab_type":"text"},"source":["### What is tensor?"]},{"cell_type":"markdown","metadata":{"id":"7yFL0FkgmDsi","colab_type":"text"},"source":["Tensor is multidimensional array or matrix."]},{"cell_type":"markdown","metadata":{"id":"dRFEO-6VmPyA","colab_type":"text"},"source":["### Composing models in Keras"]},{"cell_type":"markdown","metadata":{"id":"nBMvIR0FmTpA","colab_type":"text"},"source":["#### Sequential composition"]},{"cell_type":"markdown","metadata":{"id":"dT4tF8pdmaV7","colab_type":"text"},"source":["The first one is the sequential composition, where different predefined models are stacked\n","together in a linear pipeline of layers similar to a stack or a queue."]},{"cell_type":"markdown","metadata":{"id":"M3abZYMwmhV7","colab_type":"text"},"source":["#### Functional composition"]},{"cell_type":"markdown","metadata":{"id":"vhrZ5pe5mtex","colab_type":"text"},"source":["The second way of composing modules is via the functional API, where it is possible to\n","define complex models, such as directed acyclic graphs, models with shared layers, or\n","multi-output models."]},{"cell_type":"markdown","metadata":{"id":"si4tWpTBmymU","colab_type":"text"},"source":["### An overview of predefined neural network layers"]},{"cell_type":"markdown","metadata":{"id":"86wwwMbEnmsa","colab_type":"text"},"source":["- Regular dense is a fully connected neural network layer."]},{"cell_type":"code","metadata":{"id":"hQR9VNuhpBy2","colab_type":"code","colab":{}},"source":["# keras.layers.Dense(units, activation=None, use_bias=True, \n","#                    kernel_initializer='glorot_uniform', \n","#                    bias_initializer='zeros', kernel_regularizer=None, \n","#                    bias_regularizer=None, activity_regularizer=None, \n","#                    kernel_constraint=None, bias_constraint=None)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CgrGDD67pD0D","colab_type":"text"},"source":["- Recurrent neural networks are a class of neural networks that exploit the sequential nature of their input.Such inputs could be a text, a speech, time series, and anything else where the\n","occurrence of an element in the sequence is dependent on the elements that appeared before\n","it.\n"]},{"cell_type":"markdown","metadata":{"id":"vnlwY2SZpHDk","colab_type":"text"},"source":["- ConvNets are a class of neural networks using convolutional and pooling operations for preogressively learning rather sophisticated models based on progressive levels of abstraction."]},{"cell_type":"markdown","metadata":{"id":"sxUMj4ugpiUl","colab_type":"text"},"source":["### Regularization"]},{"cell_type":"markdown","metadata":{"id":"6h-fgTF7pkg-","colab_type":"text"},"source":["Regularization is a way to prevent overfitting. \n","- kernel_regulizer: regulizer function applied to the weight matrix\n","- bias_regulizer: regulier function applied to the bias vector\n","- activity_regulizer: regulizer function applied to the output of the layer (its activation)\n","- Using dropout\n","    - rate: 0-1, represents the fraction of the input units to drop\n","    - noise_shape: It is a 1D integer tensor which represents the shape of the binary\n","dropout mask that will be multiplied with the input.\n","    - seed: it is an integer which is used as random seed\n"]},{"cell_type":"markdown","metadata":{"id":"kQQvPVgjqzEN","colab_type":"text"},"source":["Batch normalization is a way to accelerate learning and generally achieve better accuracy."]},{"cell_type":"markdown","metadata":{"id":"1fdT93y-rPML","colab_type":"text"},"source":["### An overview of losses functions\n","\n","- Accuracy which is used for classification problems. There are multiple choices:\n","binary_accuracy (mean accuracy rate across all predictions for binary\n","classification problems), categorical_accuracy (mean accuracy rate across all\n","predictions for multiclass classification problems),\n","sparse_categorical_accuracy(useful for sparse targets), and\n","top_k_categorical_accuracy(success when the target class is within the\n","top_k predictions provided).\n","- Error loss, which measures the difference between the values predicted and the\n","values actually observed. There are multiple choices: mse (mean square error\n","between predicted and target values), rmse (root square error between predicted\n","and target values), mae (mean absolute error between predicted and target\n","values), mape (mean percentage error between predicted and target values), and\n","msle (mean squared logarithmic error between predicted and target values).\n","- Hinge loss, which is generally used for training classifiers. There are two\n","versions: hinge defined as and squared hinge defined as max(1 - ytrue * ypred)\n","the squared value of the hinge loss.\n","- Class loss is used to calculate the cross-entropy for classification problems. There\n","are multiple versions, including binary cross-entropy, and categorical crossentropy."]},{"cell_type":"markdown","metadata":{"id":"7a3EJbrHtQua","colab_type":"text"},"source":["## Some Useful Operations"]},{"cell_type":"markdown","metadata":{"id":"wsBUWYk6uLJ1","colab_type":"text"},"source":["### Saving and loading the weights and the architecture of a model"]},{"cell_type":"code","metadata":{"id":"qwOOnX-7uUYs","colab_type":"code","colab":{}},"source":["### Model Architecture\n","\n","# # save as JSON \n","# json_string = model.to_json()\n","# # sve as YAML \n","# yaml_string = model.to_yaml()\n","# # model reconsttruction from JSON\n","# from keras.models import model_from_json\n","# model = model_from_json(json_string)\n","# # model reconstruction from YAML\n","# from keras.models import model_from_yaml\n","# model = model_from_yaml(yaml_string)\n","\n","\n","### Model parameters (weights)\n","# from keras.models import load_model\n","# model.save('my_model.h5')"],"execution_count":0,"outputs":[]}]}