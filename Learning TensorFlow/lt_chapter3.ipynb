{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lt-chapter3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KPh64vyihvbe",
        "colab_type": "text"
      },
      "source": [
        "# Chapter 3\n",
        "# Understanding TensorFlow Basics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjDf2S3fjPyG",
        "colab_type": "text"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBW4G8Cnl1My",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R06CjmtgjVH4",
        "colab_type": "text"
      },
      "source": [
        "## Computation Graphs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EHvvs0GxjXLn",
        "colab_type": "text"
      },
      "source": [
        "TensorFlow allows us to implement machine learning algorithms by creating and\n",
        "computing operations that interact with one another. These interactions form what\n",
        "we call a “computation graph,” with which we can intuitively represent complicated\n",
        "functional architectures."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6Pz_R6Ljj-1",
        "colab_type": "text"
      },
      "source": [
        "### What is a Computation Graph"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i9VD02P5jm7O",
        "colab_type": "text"
      },
      "source": [
        "A graph refers to a set of interconnected\n",
        "entities, commonly called nodes or vertices. These nodes are connected to each\n",
        "other via edges. In a dataflow graph, the edges allow data to “flow” from one node to\n",
        "another in a directed manner."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ScmUgCcPjwJC",
        "colab_type": "text"
      },
      "source": [
        "### The Benefits of Graph Computations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZAgH242kEwJ",
        "colab_type": "text"
      },
      "source": [
        "TensorFlow optimizes its computations based on the graph’s connectivity. Each graph\n",
        "has its own set of node dependencies. When the input of node y is affected by the\n",
        "output of node x, we say that node y is dependent on node x. We call it a direct\n",
        "dependency when the two are connected via an edge, and an indirect dependency\n",
        "otherwise."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "csEYSFlxkaRG",
        "colab_type": "text"
      },
      "source": [
        "We can always identify the full set of dependencies for each node in the graph. This is\n",
        "a fundamental characteristic of the graph-based computation format. Being able to\n",
        "locate dependencies between units of our model allows us to both distribute computations\n",
        "across available resources and avoid performing redundant computations of\n",
        "irrelevant subsets, resulting in a faster and more efficient way of computing things."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BSBEJGVQk48T",
        "colab_type": "text"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dVDGMQWKk-Yu",
        "colab_type": "text"
      },
      "source": [
        "## Graphs, Sessions, and Fetches"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e3rAj2F6lAqS",
        "colab_type": "text"
      },
      "source": [
        "Roughly speaking, working with TensorFlow involves two main phases: (1) constructing\n",
        "a graph and (2) executing it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P3167GA0lEPh",
        "colab_type": "text"
      },
      "source": [
        "### Creating a Graph"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "675GYZRIlG00",
        "colab_type": "text"
      },
      "source": [
        "Right after we import TensorFlow (with import tensorflow as tf), a specific\n",
        "empty default graph is formed. All the nodes we create are automatically associated\n",
        "with that default graph."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJ3V892nlNPc",
        "colab_type": "text"
      },
      "source": [
        "Using the tf.\\<operator\\> methods, we will create six nodes assigned to arbitrarily\n",
        "named variables. The contents of these variables should be regarded as the output of\n",
        "the operations, and not the operations themselves. For now we refer to both the operations\n",
        "and their outputs with the names of their corresponding variables."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Og_dOl5DlZKt",
        "colab_type": "code",
        "outputId": "774305ac-74d0-4c54-9619-e12b4db629f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "a = tf.constant(9)\n",
        "b = tf.constant(6)\n",
        "c = tf.constant(3)\n",
        "\n",
        "d = tf.multiply(a, b)\n",
        "e = tf.add(c, b)\n",
        "f = tf.subtract(d, e)\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    print(sess.run(f))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "45\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CzZQbS_4mfOk",
        "colab_type": "text"
      },
      "source": [
        "First, we launch the graph in a tf.Session. A Session object is the part of the TensorFlow\n",
        "API that communicates between Python objects and data on our end, and\n",
        "the actual computational system where memory is allocated for the objects we define,\n",
        "intermediate variables are stored, and finally results are fetched for us."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CmLCdI-hn8pq",
        "colab_type": "text"
      },
      "source": [
        "The execution itself is then done with the .run() method of the Session\n",
        "object. When called, this method completes one set of computations in our graph in\n",
        "the following manner: it starts at the requested output(s) and then works backward,\n",
        "computing nodes that must be executed according to the set of dependencies. Therefore,\n",
        "the part of the graph that will be computed depends on our output query."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQyEw7eqoQXN",
        "colab_type": "text"
      },
      "source": [
        "### Constructing and Managing Our Graph"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qTcQGwILo8nq",
        "colab_type": "text"
      },
      "source": [
        "As mentioned, as soon as we import TensorFlow, a default graph is automatically created\n",
        "for us. We can create additional graphs and control their association with some\n",
        "given operations. tf.Graph() creates a new graph, represented as a TensorFlow\n",
        "object. In this example we create another graph and assign it to the variable g:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wyc3zvy_pDPS",
        "colab_type": "code",
        "outputId": "fd58b76d-f86f-4b47-e1d9-00ea2121b2e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "print(tf.get_default_graph())\n",
        "\n",
        "g = tf.Graph()\n",
        "print(g)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<tensorflow.python.framework.ops.Graph object at 0x7f800312e9b0>\n",
            "<tensorflow.python.framework.ops.Graph object at 0x7f800318c550>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g7urXYenpJsp",
        "colab_type": "text"
      },
      "source": [
        "At this point we have two graphs: the default graph and the empty graph in g. Both\n",
        "are revealed as TensorFlow objects when printed. Since g hasn’t been assigned as the\n",
        "default graph, any operation we create will not be associated with it, but rather with\n",
        "the default one."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZy5m04-pWYX",
        "colab_type": "code",
        "outputId": "da200e52-f6b0-40c8-edb8-25cb416f25a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "g = tf.Graph()\n",
        "a = tf.constant(3)\n",
        "\n",
        "print(a.graph is g)\n",
        "print(a.graph is tf.get_default_graph())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "False\n",
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yct1e-H4plE2",
        "colab_type": "text"
      },
      "source": [
        "To make sure our constructed nodes are associated with the right graph we can construct\n",
        "them using a very useful Python construct: the with statement."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OCrJuiBipzMg",
        "colab_type": "text"
      },
      "source": [
        "We use the with statement together with the as_default() command, which returns\n",
        "a context manager that makes this graph the default one. This comes in handy when\n",
        "working with multiple graphs:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8cg0kHBqHzA",
        "colab_type": "code",
        "outputId": "722f8452-03b4-4644-953d-aa1284b36af9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "g1 = tf.get_default_graph()\n",
        "g2 = tf.Graph()\n",
        "\n",
        "print(g1 is tf.get_default_graph())\n",
        "\n",
        "with g2.as_default():\n",
        "    print(g2 is tf.get_default_graph())\n",
        "\n",
        "print(g2 is tf.get_default_graph())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n",
            "True\n",
            "False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Un1RBFeWqb7-",
        "colab_type": "text"
      },
      "source": [
        "### Fetches"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jx3bzQcWqkkO",
        "colab_type": "text"
      },
      "source": [
        "In our initial graph example, we request one specific node (node f) by passing the\n",
        "variable it was assigned to as an argument to the sess.run() method. This argument\n",
        "is called fetches, corresponding to the elements of the graph we wish to compute.\n",
        "We can also ask sess.run() for multiple nodes’ outputs simply by inputting a\n",
        "list of requested nodes:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UkxI140hq2tv",
        "colab_type": "code",
        "outputId": "7cb35ff4-186e-4593-eab3-d4d6c1eea49a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "with tf.Session() as sess:\n",
        "    fetches = [a, b, c, d, e, f]\n",
        "    output = sess.run(fetches)\n",
        "\n",
        "print(output)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[3, 6, 3, 54, 9, 45]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iiVSzRc7rE0M",
        "colab_type": "text"
      },
      "source": [
        "We mentioned that TensorFlow computes only the essential nodes according to the\n",
        "set of dependencies. This is also manifested in our example: when we ask for the output\n",
        "of node d, only the outputs of nodes a and b are computed. This is a great advantage of TensorFlow—it doesn’t matter\n",
        "how big and complicated our graph is as a whole, since we can run just a small portion\n",
        "of it as needed.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WhRbNkddrtRu",
        "colab_type": "text"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LnKN9QhsrzOc",
        "colab_type": "text"
      },
      "source": [
        "## Flowing Tensors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4YJALnS-r098",
        "colab_type": "text"
      },
      "source": [
        "### Nodes are Operations, Edges are Tensor Objects"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N91WN5_9UIxz",
        "colab_type": "text"
      },
      "source": [
        "TensorFlow is designed such that first a skeleton graph is created with all of its components.\n",
        "At this point no actual data flows in it and no computations take place. It is\n",
        "only upon execution, when we run the session, that data enters the graph and computations occur. This way, computations can be much more\n",
        "efficient, taking the entire graph structure into consideration."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qE2yxEA0VTXn",
        "colab_type": "text"
      },
      "source": [
        "tf.constant() created a node with the corresponding\n",
        "passed value. Printing the output of the constructor, we see that it’s actually\n",
        "a Tensor object instance. These objects have methods and attributes that control their\n",
        "behavior and that can be defined upon creation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vzc-K2tpVYhy",
        "colab_type": "code",
        "outputId": "d0b6f864-ce73-4e3c-ced8-b3c182dd2a5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "c = tf.constant(9.0)\n",
        "print(c)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"Const:0\", shape=(), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PUm-C7ZpVgcZ",
        "colab_type": "text"
      },
      "source": [
        "Each Tensor object in TensorFlow has attributes such as name, shape, and dtype that\n",
        "help identify and set the characteristics of that object. These attributes are optional when creating a node, and are set automatically by TensorFlow when missing. In the\n",
        "next section we will take a look at these attributes. We will do so by looking at Tensor\n",
        "objects created by ops known as source operations. Source operations are operations\n",
        "that create data, usually without using any previously processed inputs. With these\n",
        "operations we can create scalars, as we already encountered with the tf.constant()\n",
        "method, as well as arrays and other types of data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jfcIbwwSWAjJ",
        "colab_type": "text"
      },
      "source": [
        "### Data Types"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VeMVqaQYWCFS",
        "colab_type": "text"
      },
      "source": [
        "The basic units of data that pass through a graph are numerical, Boolean, or string\n",
        "elements. When we print out the Tensor object c from our last code example, we see\n",
        "that its data type is a floating-point number. Since we didn’t specify the type of data,\n",
        "TensorFlow inferred it automatically. For example 5 is regarded as an integer, while\n",
        "anything with a decimal point, like 5.1, is regarded as a floating-point number."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LW5T_ZD_WOdT",
        "colab_type": "code",
        "outputId": "1a377586-fd5a-416e-b487-fb53bdb92267",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "# we can set data type by specifying attribute dtype\n",
        "c = tf.constant(9, dtype=tf.float32)\n",
        "print(c)\n",
        "print(c.name)\n",
        "print(c.shape)\n",
        "print(c.dtype)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"Const_1:0\", shape=(), dtype=float32)\n",
            "Const_1:0\n",
            "()\n",
            "<dtype: 'float32'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AzBPARn5WmNS",
        "colab_type": "text"
      },
      "source": [
        "#### Casting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJe9Xy7mWr-4",
        "colab_type": "text"
      },
      "source": [
        "It is important to make sure our data types match throughout the graph—performing\n",
        "an operation with two nonmatching data types will result in an exception. To change\n",
        "the data type setting of a Tensor object, we can use the tf.cast() operation, passing\n",
        "the relevant Tensor and the new data type of interest as the first and second arguments,\n",
        "respectively:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2XZkZ6zBWzCG",
        "colab_type": "code",
        "outputId": "e3ab02dc-bef4-4046-d301-084600f577ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "x = tf.constant([1, 2, 3], name='x', dtype=tf.float32)\n",
        "print(x.name, x.shape, x.dtype)\n",
        "x = tf.cast(x, dtype=tf.int64)\n",
        "print(x.name, x.shape, x.dtype)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x:0 (3,) <dtype: 'float32'>\n",
            "Cast:0 (3,) <dtype: 'int64'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_98efBiXF4n",
        "colab_type": "text"
      },
      "source": [
        "### Tensor Arrays and Shapes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ye6LEy2-XR9N",
        "colab_type": "code",
        "outputId": "24111ed2-6be6-45c3-ad30-247f28e85583",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "c = tf.constant(np.random.randint(0, 10, size=(2, 2)))\n",
        "print(c.shape)\n",
        "c = tf.constant(np.random.randint(0, 10, size=(3, 3, 3)))\n",
        "print(c.get_shape())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2, 2)\n",
            "(3, 3, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NGRoU3DYZP5F",
        "colab_type": "text"
      },
      "source": [
        "Random-number generators have special importance as they are used in many cases\n",
        "to create the initial values for TensorFlow Variables, which will be introduced\n",
        "shortly. For example, we can generate random numbers from a normal distribution\n",
        "using tf.random.normal(), passing the shape, mean, and standard deviation as the\n",
        "first, second, and third arguments, respectively. Another two examples for useful random\n",
        "initializers are the truncated normal that, as its name implies, cuts off all values\n",
        "below and above two standard deviations from the mean, and the uniform initializer\n",
        "that samples values uniformly within some interval [a,b)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ArQtTWTlaC6C",
        "colab_type": "code",
        "outputId": "94e88faf-23dc-49ce-f853-6406b9279e88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "seq = tf.linspace(0.0, 10.0, 10, name='seq')\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    print(sess.run(seq))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 0.         1.1111112  2.2222223  3.3333335  4.4444447  5.555556\n",
            "  6.666667   7.777778   8.888889  10.       ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5GDBBHjqaUS0",
        "colab_type": "text"
      },
      "source": [
        "A feature that is convenient to use when we want to explore the data content of an\n",
        "object is tf.InteractiveSession(). Using it and the .eval() method, we can get a\n",
        "full look at the values without the need to constantly refer to the session object. tf.InteractiveSession() allows you to replace the usual tf.Ses\n",
        "sion(), so that you don’t need a variable holding the session for\n",
        "running ops. This can be useful in interactive Python environments,\n",
        "like when writing IPython notebooks, for instance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mK2qxNIJa5p_",
        "colab_type": "code",
        "outputId": "c2c50ee3-960e-40b2-8358-1c71a439b724",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        }
      },
      "source": [
        "sess = tf.InteractiveSession()\n",
        "seq = tf.random.normal(shape=(2, 2), seed=42)\n",
        "print(seq.eval())\n",
        "sess.close()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-0.28077507 -0.1377521 ]\n",
            " [-0.6763296   0.02458041]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py:1750: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
            "  warnings.warn('An interactive session is already active. This can '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0S46r9BbYOn",
        "colab_type": "text"
      },
      "source": [
        "#### Matrix multiplication"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EzuBf-X0cHMd",
        "colab_type": "code",
        "outputId": "6f0018c3-f34a-4476-80b4-b8271b8eac30",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "A = tf.constant([[1, 2, 3],\n",
        "                 [4, 5, 6]])\n",
        "print(A.get_shape())\n",
        "x = tf.constant([1, 0, 1])\n",
        "print(x.get_shape())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2, 3)\n",
            "(3,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U5Lu1JKscmBP",
        "colab_type": "text"
      },
      "source": [
        "We cannot just use tf.matmul to A and x. Before that, we have to transform x which is a 1D vector to a 2D single-column matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_LKHgz2Tc1jt",
        "colab_type": "code",
        "outputId": "cf0c73c6-cc39-4a84-d5fe-6ec227e1cab4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "with tf.Session() as sess:\n",
        "    print(sess.run(A))\n",
        "    print(sess.run(x))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1 2 3]\n",
            " [4 5 6]]\n",
            "[1 0 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "apcD0q4OdFDM",
        "colab_type": "code",
        "outputId": "8b162313-b0ae-4224-cb8f-36eb8b6ae674",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "x = tf.expand_dims(x, 1)\n",
        "\n",
        "with tf.Session()as sess:\n",
        "    print(sess.run(x))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1]\n",
            " [0]\n",
            " [1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kK3Jf6zAdXMc",
        "colab_type": "code",
        "outputId": "c3341655-3dbd-4bfe-acee-10abf81b1999",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "x = tf.constant([1, 0, 1])\n",
        "x = tf.expand_dims(x, 0)\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    print(sess.run(x))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1 0 1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZYg-gxrd4I0",
        "colab_type": "code",
        "outputId": "cec3c471-bed8-446c-cb93-8204d2fb727f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        }
      },
      "source": [
        "A = tf.random.truncated_normal(shape=(3, 3), seed=42)\n",
        "x = tf.random.normal(shape=(3, 1), seed=42)\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    print(sess.run(A))\n",
        "    print(sess.run(x))\n",
        "    print(sess.run(tf.matmul(A, x)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-0.28077507 -0.1377521  -0.6763296 ]\n",
            " [ 0.02458041 -0.46845472 -0.00246632]\n",
            " [-0.9745911   0.6638492   0.4368011 ]]\n",
            "[[-0.28077507]\n",
            " [-0.1377521 ]\n",
            " [-0.6763296 ]]\n",
            "[[ 1.6274279 ]\n",
            " [-0.46013314]\n",
            " [ 1.7178389 ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4065uvDeR06",
        "colab_type": "text"
      },
      "source": [
        "### Names"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rU4CYhSeec93",
        "colab_type": "text"
      },
      "source": [
        "Each Tensor object also has an identifying name. This name is an intrinsic string\n",
        "name, not to be confused with the name of the variable. As with dtype, we can use\n",
        "the .name attribute to see the name of the object:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "calDw7GHek8x",
        "colab_type": "code",
        "outputId": "16e9ab35-cbb1-4a17-85f7-cda67d2c1636",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "with tf.Graph().as_default():\n",
        "    c1 = tf.constant(4, dtype=tf.float64, name='c')\n",
        "    c2 = tf.constant(4, dtype=tf.int32, name='c')\n",
        "print(c1.name)\n",
        "print(c2.name)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "c:0\n",
            "c_1:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fTmNNzmxfAh_",
        "colab_type": "code",
        "outputId": "8b27c748-be69-4527-c15e-90ad18b28126",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "c1 = tf.constant(4, dtype=tf.float64, name='c')\n",
        "c2 = tf.constant(4, dtype=tf.int32, name='c')\n",
        "print(c1.name)\n",
        "print(c2.name)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "c:0\n",
            "c_1:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "twvTu2_KfLnX",
        "colab_type": "text"
      },
      "source": [
        "The name of the Tensor object is simply the name of its corresponding operation (“c”;\n",
        "concatenated with a colon), followed by the index of that tensor in the outputs of the\n",
        "operation that produced it—it is possible to have more than one. Objects residing within the same graph cannot have the same name\n",
        "—TensorFlow forbids it. As a consequence, it will automatically\n",
        "add an underscore and a number to distinguish the two. Of course,\n",
        "both objects can have the same name when they are associated with\n",
        "different graphs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JhpmofnrfpXS",
        "colab_type": "text"
      },
      "source": [
        "#### Name scopes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFkHcHpDgfh1",
        "colab_type": "text"
      },
      "source": [
        "Sometimes when dealing with a large, complicated graph, we would like to create\n",
        "some node grouping to make it easier to follow and manage. For that we can hierarchically\n",
        "group nodes together by name. We do so by using tf.name_scope(\"pre\n",
        "fix\") together with the useful with clause again:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbxi7gBkgoZ6",
        "colab_type": "code",
        "outputId": "300d78dc-50a0-424b-9242-91bd599dde0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "with tf.Graph().as_default():\n",
        "    c1 = tf.constant(4, dtype=tf.float64, name='c')\n",
        "    with tf.name_scope(\"prefix_name\"):\n",
        "        c2 = tf.constant(4, dtype=tf.int32, name='c')\n",
        "        c3 = tf.constant(4, dtype=tf.float64, name='c')\n",
        "\n",
        "print(c1.name)\n",
        "print(c2.name)\n",
        "print(c3.name)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "c:0\n",
            "prefix_name/c:0\n",
            "prefix_name/c_1:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EOaEX6lRhCTh",
        "colab_type": "text"
      },
      "source": [
        "In this example we’ve grouped objects contained in variables c2 and c3 under the\n",
        "scope prefix_name, which shows up as a prefix in their names.\n",
        "Prefixes are especially useful when we would like to divide a graph into subgraphs\n",
        "with some semantic meaning. These parts can later be used, for instance, for visualization\n",
        "of the graph structure."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfY5nm8fhMSP",
        "colab_type": "code",
        "outputId": "7a689423-3e17-4df5-c18f-cff1d63a4b89",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        }
      },
      "source": [
        "g = tf.Graph()\n",
        "\n",
        "with g.as_default():\n",
        "    c1 = tf.constant(5, dtype=tf.float32, name='c')\n",
        "    with tf.name_scope(\"layer_1\"):\n",
        "        c2 = tf.constant(9, dtype=tf.int32, name='c')\n",
        "        c3 = tf.constant(7, dtype=tf.int32, name='c')\n",
        "    with tf.name_scope(\"layer_2\"):\n",
        "        c4 = tf.constant(1, dtype=tf.int32, name='c')\n",
        "        c5 = tf.constant(3, dtype=tf.int32, name='c')\n",
        "\n",
        "print(c1.graph is g)\n",
        "print()\n",
        "\n",
        "print(c1.name)\n",
        "print(c2.name)\n",
        "print(c3.name)\n",
        "print(c4.name)\n",
        "print(c5.name)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n",
            "\n",
            "c:0\n",
            "layer_1/c:0\n",
            "layer_1/c_1:0\n",
            "layer_2/c:0\n",
            "layer_2/c_1:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j6BvV946iM0K",
        "colab_type": "text"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lgY4lLWGioCS",
        "colab_type": "text"
      },
      "source": [
        "## Variables, Placeholders, and Simple Optimization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h6E5Yed-iq8h",
        "colab_type": "text"
      },
      "source": [
        "### Variables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ezNyZJDwixJu",
        "colab_type": "text"
      },
      "source": [
        "The optimization process serves to tune the parameters of some given model. For\n",
        "that purpose, TensorFlow uses special objects called Variables. Unlike other Tensor objects that are “refilled” with data each time we run the session, Variables can maintain\n",
        "a fixed state in the graph. This is important because their current state might\n",
        "influence how they change in the following iteration. Like other Tensors, Variables\n",
        "can be used as input for other operations in the graph."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wB6TqOkZjDfl",
        "colab_type": "text"
      },
      "source": [
        "Using Variables is done in two stages. First we call the tf.Variable() function in\n",
        "order to create a Variable and define what value it will be initialized with. We then\n",
        "have to explicitly perform an initialization operation by running the session with the\n",
        "tf.global_variables_initializer() method, which allocates the memory for the\n",
        "Variable and sets its initial values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jhyw1rlfjTdu",
        "colab_type": "code",
        "outputId": "c31e47b9-18e8-4b59-b466-f892a5c3afb3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        }
      },
      "source": [
        "init_val = tf.random_normal((1, 5), 0.1)\n",
        "var = tf.Variable(init_val, name='var')\n",
        "print(\"pre run: \\n{}\".format(var))\n",
        "\n",
        "init = tf.global_variables_initializer()\n",
        "with tf.Session() as sess:\n",
        "    sess.run(init)\n",
        "    post_var = sess.run(var)\n",
        "\n",
        "print(\"\\npost run: \\n{}\".format(post_var))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "pre run: \n",
            "<tf.Variable 'var_3:0' shape=(1, 5) dtype=float32_ref>\n",
            "\n",
            "post run: \n",
            "[[ 0.37189773 -0.44705704  2.4359581  -2.0406601  -0.2951817 ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7dOmGudPjuS4",
        "colab_type": "text"
      },
      "source": [
        "Note that if we run the code again, we see that a new variable is created each time, as\n",
        "indicated by the automatic concatenation of _1 to its name:\n",
        "\n",
        "This could be very inefficient when we want to reuse the model (complex models\n",
        "could have many variables!); for example, when we wish to feed it with several different\n",
        "inputs. To reuse the same variable, we can use the tf.get_variables() function\n",
        "instead of tf.Variable()."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DO_R_I-HkQyW",
        "colab_type": "text"
      },
      "source": [
        "### Placeholders"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Am_ZoT_AlHLC",
        "colab_type": "text"
      },
      "source": [
        "So far we’ve used source operations to create our input data. TensorFlow, however,\n",
        "has designated built-in structures for feeding input values. These structures are called\n",
        "placeholders. Placeholders can be thought of as empty Variables that will be filled with data later on. We use them by first constructing our graph and only when it is executed\n",
        "feeding them with the input data.\n",
        "\n",
        "Placeholders have an optional shape argument. If a shape is not fed or is passed as\n",
        "None, then the placeholder can be fed with data of any size. It is common to use\n",
        "None for the dimension of a matrix that corresponds to the number of samples (usually\n",
        "rows), while having the length of the features (usually columns) fixed:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5Xf26MglclD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ph = tf.placeholder(tf.float32, shape=(None, 10))\n",
        "# None in the 0-axis means that we do not specify \n",
        "# the number of samples "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NzV8N-1Xlyeq",
        "colab_type": "text"
      },
      "source": [
        "Whenever we define a placeholder, we must feed it with some input values or else an\n",
        "exception will be thrown. The input data is passed to the session.run() method as a\n",
        "dictionary, where each key corresponds to a placeholder variable name, and the\n",
        "matching values are the data values given in the form of a list or a NumPy array:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "awD4p8w8lzaB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# sess.run(s, feed_dict={x : X_data, w: w_data})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OvYGNySyl820",
        "colab_type": "text"
      },
      "source": [
        "Let’s see how it looks with another graph example, this time with placeholders for two\n",
        "inputs: a matrix x and a vector w. These inputs are matrix-multiplied to create a fiveunit\n",
        "vector xw and added with a constant vector b filled with the value -1. Finally, the\n",
        "variable s takes the maximum value of that vector by using the tf.reduce_max()\n",
        "operation. The word reduce is used because we are reducing a five-unit vector to a\n",
        "single scalar:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8oCd-lwmYGm",
        "colab_type": "code",
        "outputId": "14f95820-797d-46db-bb97-5494b24f199b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "x_data = np.random.randn(5, 10)\n",
        "w_data = np.random.randn(10, 1)\n",
        "\n",
        "with tf.Graph().as_default():\n",
        "    x = tf.placeholder(tf.float32, shape=(5, 10))\n",
        "    w = tf.placeholder(tf.float32, shape=(10, 1))\n",
        "    b = tf.fill((5, 1), -1.)\n",
        "    xw = tf.matmul(x, w)\n",
        "\n",
        "    xwb = xw + b\n",
        "    s = tf.reduce_max(xwb)\n",
        "    with tf.Session() as sess:\n",
        "        outs = sess.run(s, feed_dict={x: x_data, w: w_data})\n",
        "\n",
        "print(\"Outs: {}\".format(outs))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Outs: 7.539361000061035\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9TqpS_wSnH1R",
        "colab_type": "text"
      },
      "source": [
        "### Optimization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jq5W2GETneiw",
        "colab_type": "text"
      },
      "source": [
        "#### Training to predict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yKzhPWC2npxE",
        "colab_type": "text"
      },
      "source": [
        "We have some target variable y, which we want to explain using some feature vector\n",
        "x. To do so, we first choose a model that relates the two. Our training data points will\n",
        "be used for “tuning” the model so that it best captures the desired relation. In the following\n",
        "chapters we focus on deep neural network models, but for now we will settle\n",
        "for a simple regression problem."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2VWhgx8goMGC",
        "colab_type": "text"
      },
      "source": [
        "Let’s start by describing our regression model:\n",
        "\n",
        "$f(x_i) = w^Tx_i + b$\n",
        "\n",
        "$y_i = f(x_i) + \\epsilon_i$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IkrvKOSjoPFf",
        "colab_type": "text"
      },
      "source": [
        "f(xi) is assumed to be a linear combination of some input data xi, with a set of\n",
        "weights w and an intercept b. Our target output yi is a noisy version of f(xi) after being\n",
        "summed with Gaussian noise εi (where i denotes a given sample)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9ENiFtopOKV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# x = tf.placeholder(tf.float32, shape=[None, 3])\n",
        "# y_true = tf.placeholder(tf.float32, shape=None)\n",
        "# w = tf.Variable([[0, 0, 0]], dtype=tf.float32, name='weights')\n",
        "# b = tf.Variable(0, dtype=tf.float32, name='bias')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bVjv_happ76I",
        "colab_type": "text"
      },
      "source": [
        "Once the placeholders and Variables are defined, we can write down our model. In\n",
        "this example, it’s simply a multivariate linear regression—our predicted output\n",
        "y_pred is the result of a matrix multiplication of our input container x and our\n",
        "weights w plus a bias term b:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7DyJ2DUp80J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# y_pred = tf.matmul(w, tf.transpose(x)) + b"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tixqfWiEqFX_",
        "colab_type": "text"
      },
      "source": [
        "#### Defining a loss function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-M7tMSBqH3a",
        "colab_type": "text"
      },
      "source": [
        "Next, we need a good measure with which we can evaluate the model’s performance.\n",
        "To capture the discrepancy between our model’s predictions and the observed targets,\n",
        "we need a measure reflecting “distance.” This distance is often referred to as an\n",
        "objective or a loss function, and we optimize the model by finding the set of parameters\n",
        "(weights and bias in this case) that minimize it.\n",
        "\n",
        "\n",
        "There is no ideal loss function, and choosing the most suitable one is often a blend of\n",
        "art and science. The choice may depend on several factors, like the assumptions of\n",
        "our model, how easy it is to minimize, and what types of mistakes we prefer to avoid."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AbJwKg19qcvj",
        "colab_type": "text"
      },
      "source": [
        "#### MSE and cross entropy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q4AAZyueqhiR",
        "colab_type": "text"
      },
      "source": [
        "$L(y, \\hat{y}) = \\frac{1}{n}\\sum_{i=1}^{n}(y_i - \\hat{y}_i)^2$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KfKIdCmgq4oC",
        "colab_type": "text"
      },
      "source": [
        "In our linear regression example, we take the difference between the vector y_true\n",
        "(y), the true targets, and y_pred (ŷ), the model’s predictions, and use tf.square() to\n",
        "compute the square of the difference vector. This operation is applied element-wise.\n",
        "We then average the squared differences using the tf.reduce_mean() function:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xd3basAnrHAB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# loss = tf.reduce_mean(tf.square(y_true - y_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "piFBg5PKrUuq",
        "colab_type": "text"
      },
      "source": [
        "Another very common loss, especially for categorical data, is the cross entropy, which\n",
        "we used in the softmax classifier in the previous chapter. The cross entropy is given\n",
        "by\n",
        "\n",
        "$H(p, q) = -\\sum_x p(x)log\\:q(x)$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rwv9UalarVyC",
        "colab_type": "text"
      },
      "source": [
        "and for classification with a single correct label (as is the case in an overwhelming\n",
        "majority of the cases) reduces to the negative log of the probability placed by the classifier\n",
        "on the correct label."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WOuiDdcVr4X5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# loss = tf.nn.sigmoid_cross_entropy_with_logits(labels=y_true, logits=y_pred)\n",
        "# loss = tf.reduce_mean(loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q9AAltzNsG_E",
        "colab_type": "text"
      },
      "source": [
        "#### The gradient descent optimizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UsPX-YAPsKQX",
        "colab_type": "text"
      },
      "source": [
        "The next thing we need to figure out is how to minimize the loss function. While in\n",
        "some cases it is possible to find the global minimum analytically (when it exists), in\n",
        "the great majority of cases we will have to use an optimization algorithm. Optimizers\n",
        "update the set of weights iteratively in a way that decreases the loss over time.\n",
        "\n",
        "The most commonly used approach is gradient descent, where we use the loss’s gradient\n",
        "with respect to the set of weights. In slightly more technical terms, if our loss is\n",
        "some multivariate function F(w̄), then in the neighborhood of some point w ̄0\n",
        ", the\n",
        "“steepest” direction of decrease of F(w̄) is obtained by moving from w ̄0\n",
        "in the direction\n",
        "of the negative gradient of F at w ̄0.\n",
        "\n",
        "So if w ̄1\n",
        "= w ̄0\n",
        "-γ∇F(w ̄0\n",
        ") where ∇F(w ̄0\n",
        ") is the gradient of F evaluated at w ̄0\n",
        ", then for a\n",
        "small enough γ:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-mrOJAJslK2",
        "colab_type": "text"
      },
      "source": [
        "The gradient descent algorithms work well on highly complicated network architectures\n",
        "and therefore are suitable for a wide variety of problems. More specifically,\n",
        "recent advances make it possible to compute these gradients by utilizing massively\n",
        "parallel systems, so the approach scales well with dimensionality (though it can still\n",
        "be painfully time-consuming for large real-world problems). While convergence to\n",
        "the global minimum is guaranteed for convex functions, for nonconvex problems\n",
        "(which are essentially all problems in the world of deep learning) they can get stuck\n",
        "in local minima. In practice, this is often good enough, as is evidenced by the huge\n",
        "success of the field of deep learning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W88V2RyPs6oD",
        "colab_type": "text"
      },
      "source": [
        "#### Sampling methods"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0lBGyBKfs9FZ",
        "colab_type": "text"
      },
      "source": [
        "The gradient of the objective is computed with respect to the model parameters and\n",
        "evaluated using a given set of input samples, xs. How many of the samples should we\n",
        "take for this calculation? Intuitively, it makes sense to calculate the gradient for the\n",
        "entire set of samples in order to benefit from the maximum amount of available\n",
        "information. This method, however, has some shortcomings. For example, it can be\n",
        "very slow and is intractable when the dataset requires more memory than is available.\n",
        "\n",
        "A more popular technique is the stochastic gradient descent (SGD), where instead of\n",
        "feeding the entire dataset to the algorithm for the computation of each step, a subset\n",
        "of the data is sampled sequentially. The number of samples ranges from one sample at\n",
        "a time to a few hundred, but the most common sizes are between around 50 to\n",
        "around 500 (usually referred to as mini-batches).\n",
        "\n",
        "Using smaller batches usually works faster, and the smaller the size of the batch, the\n",
        "faster are the calculations. However, there is a trade-off in that small samples lead to\n",
        "lower hardware utilization and tend to have high variance, causing large fluctuations\n",
        "to the objective function. Nevertheless, it turns out that some fluctuations are beneficial\n",
        "since they enable the set of parameters to jump to new and potentially better local\n",
        "minima. Using a relatively smaller batch size is therefore effective in that regard, and\n",
        "is currently overall the preferred approach."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZsjIyIt3tTKv",
        "colab_type": "text"
      },
      "source": [
        "#### Gradient descent in TensorFlow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WJMlS4Qytks4",
        "colab_type": "text"
      },
      "source": [
        "TensorFlow makes it very easy and intuitive to use gradient descent algorithms. Optimizers\n",
        "in TensorFlow compute the gradients simply by adding new operations to the\n",
        "graph, and the gradients are calculated using automatic differentiation. This means,\n",
        "in general terms, that TensorFlow automatically computes the gradients on its own,\n",
        "“deriving” them from the operations and structure of the computation graph."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LtF7Oq3itxdE",
        "colab_type": "text"
      },
      "source": [
        "An important parameter to set is the algorithm’s learning rate, determining how\n",
        "aggressive each update iteration will be (or in other words, how large the step will be\n",
        "in the direction of the negative gradient). We want the decrease in the loss to be fast\n",
        "enough on the one hand, but on the other hand not large enough so that we overshoot\n",
        "the target and end up at a point with a higher value of the loss function."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UnJmSsILt_29",
        "colab_type": "text"
      },
      "source": [
        "We first create an optimizer by using the GradientDescentOptimizer() function\n",
        "with the desired learning rate. We then create a train operation that updates our variables\n",
        "by calling the optimizer.minimize() function and passing in the loss as an\n",
        "argument:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGhIv6yYuJxw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
        "# train = optimizer.minimize(loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9F0HB3IsuVP8",
        "colab_type": "text"
      },
      "source": [
        "#### Wrapping it up with examples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aHBq-fLuuYbK",
        "colab_type": "text"
      },
      "source": [
        "##### Example 1: Linear Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9KUR4yOuhvg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# === Create data and simulate results ===\n",
        "x_data = np.random.randn(2000, 3)\n",
        "w_real = [0.3, 0.5, 0.1]\n",
        "b_real = -0.2\n",
        "\n",
        "noise = np.random.randn(1, 2000) * 0.1\n",
        "y_data = np.matmul(w_real, x_data.T) + b_real + noise"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0yB5O-Vbvh8N",
        "colab_type": "text"
      },
      "source": [
        "Next, we estimate our set of weights w and bias b by optimizing the model (i.e., finding\n",
        "the best parameters) so that its predictions match the real targets as closely as\n",
        "possible. Each iteration computes one update to the current parameters. In this example\n",
        "we run 10 iterations, printing our estimated parameters every 5 iterations using\n",
        "the sess.run() method."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJ58cuqVwM5z",
        "colab_type": "text"
      },
      "source": [
        "Don’t forget to initialize the variables! In this example we initialize both the weights\n",
        "and the bias with zeros; however, there are “smarter” initialization techniques to\n",
        "choose, as we will see in the next chapters. We use name scopes to group together\n",
        "parts that are related to inferring the output, defining the loss, and setting and creating\n",
        "the train object:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TXM74aSrwSJN",
        "colab_type": "code",
        "outputId": "4e09c38c-3f36-4e39-e236-c51f89661b9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        }
      },
      "source": [
        "NUM_STEPS = 10\n",
        "\n",
        "g = tf.Graph() # building specific graph\n",
        "wb_ = [] # weights\n",
        "with g.as_default():\n",
        "    x = tf.placeholder(tf.float32, shape=[None, 3]) # input\n",
        "    y_true = tf.placeholder(tf.float32, shape=None) # input\n",
        "\n",
        "    with tf.name_scope('inference') as scope:\n",
        "        w = tf.Variable([[0, 0, 0]], dtype=tf.float32, name='weights')\n",
        "        b = tf.Variable(0, dtype=tf.float32, name='bias')\n",
        "        y_pred = tf.matmul(w, tf.transpose(x)) + b\n",
        "\n",
        "    with tf.name_scope('loss') as scope:\n",
        "        loss = tf.reduce_mean(tf.square(y_true - y_pred))\n",
        "\n",
        "    with tf.name_scope('train') as scope:\n",
        "        learning_rate = 0.5\n",
        "        optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
        "        train = optimizer.minimize(loss)\n",
        "\n",
        "    # before starting, initialize the variables\n",
        "    init = tf.global_variables_initializer()\n",
        "    with tf.Session() as sess:\n",
        "        sess.run(init)\n",
        "        for step in range(NUM_STEPS):\n",
        "            sess.run(train, feed_dict={x: x_data, y_true: y_data})\n",
        "            if (step%5 == 0):\n",
        "                print(step, sess.run([w, b]))\n",
        "                wb_.append(sess.run([w, b]))\n",
        "\n",
        "        print(10, sess.run([w, b]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 [array([[0.3082251 , 0.5072045 , 0.09721694]], dtype=float32), -0.1795402]\n",
            "5 [array([[0.30226943, 0.498831  , 0.09799903]], dtype=float32), -0.1993168]\n",
            "10 [array([[0.30226943, 0.498831  , 0.09799903]], dtype=float32), -0.19931678]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FNXJ_QSFyamt",
        "colab_type": "text"
      },
      "source": [
        "##### Example 2: Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acVf40nTzUWi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "N = 20000\n",
        "\n",
        "def sigmoid(x):\n",
        "    return 1 / (x + np.exp(-x))\n",
        "\n",
        "# ===== Create data =====\n",
        "x_data = np.random.randn(N, 3)\n",
        "w_real = [0.3, 0.5, 0.1]\n",
        "b_real = -0.2\n",
        "wxb = np.matmul(w_real, x_data.T) + b_real\n",
        "\n",
        "y_data_pre_noise = sigmoid(wxb)\n",
        "y_data = np.random.binomial(1, y_data_pre_noise)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m6zRFz4O0C4h",
        "colab_type": "code",
        "outputId": "8804ab22-6181-4ceb-9a11-8f8b7cde1f59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "NUM_STEPS = 50\n",
        "\n",
        "\n",
        "with \n",
        "\n",
        "init = tf.global_variables_initializer()\n",
        "with tf.Session() as sess:\n",
        "    sess.run(inint)\n",
        "    for i in range(NUM_STEPS):\n",
        "        sess.run(train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7nWMYVZ0FEi",
        "colab_type": "code",
        "outputId": "4ded2903-6c7a-44d4-d449-b602b12e4a6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 239
        }
      },
      "source": [
        "NUM_STEPS = 50\n",
        "\n",
        "g = tf.Graph() # building specific graph\n",
        "wb_ = [] # weights\n",
        "with g.as_default():\n",
        "    x = tf.placeholder(tf.float32, shape=[None, 3]) # input\n",
        "    y_true = tf.placeholder(tf.float32, shape=None) # input\n",
        "\n",
        "    with tf.name_scope('inference') as scope:\n",
        "        w = tf.Variable([[0, 0, 0]], dtype=tf.float32, name='weights')\n",
        "        b = tf.Variable(0, dtype=tf.float32, name='bias')\n",
        "        y_pred = tf.matmul(w, tf.transpose(x)) + b\n",
        "\n",
        "    with tf.name_scope('loss') as scope:\n",
        "        loss = tf.nn.sigmoid_cross_entropy_with_logits(labels=y_true, logits=y_pred)\n",
        "        loss = tf.reduce_mean(loss)\n",
        "\n",
        "    with tf.name_scope('train') as scope:\n",
        "        learning_rate = 0.5\n",
        "        optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
        "        train = optimizer.minimize(loss)\n",
        "\n",
        "    # before starting, initialize the variables\n",
        "    init = tf.global_variables_initializer()\n",
        "    with tf.Session() as sess:\n",
        "        sess.run(init)\n",
        "        for step in range(NUM_STEPS):\n",
        "            sess.run(train, feed_dict={x: x_data, y_true: y_data})\n",
        "            if (step%5 == 0):\n",
        "                print(step, sess.run([w, b]))\n",
        "                wb_.append(sess.run([w, b]))\n",
        "\n",
        "        print(50, sess.run([w, b]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 [array([[0.02830815, 0.04464366, 0.00892977]], dtype=float32), 0.17637569]\n",
            "5 [array([[0.12645872, 0.20251669, 0.03831439]], dtype=float32), 0.7850605]\n",
            "10 [array([[0.18835798, 0.30481362, 0.05564939]], dtype=float32), 1.1303365]\n",
            "15 [array([[0.23494191, 0.38290447, 0.0683545 ]], dtype=float32), 1.3478993]\n",
            "20 [array([[0.27262336, 0.4465248 , 0.07856297]], dtype=float32), 1.4956505]\n",
            "25 [array([[0.303922  , 0.49957046, 0.08705515]], dtype=float32), 1.6015068]\n",
            "30 [array([[0.33017766, 0.5441667 , 0.09421503]], dtype=float32), 1.6804487]\n",
            "35 [array([[0.35229072, 0.5817769 , 0.10028522]], dtype=float32), 1.7411702]\n",
            "40 [array([[0.37095195, 0.61354333, 0.10544523]], dtype=float32), 1.7890242]\n",
            "45 [array([[0.38672286, 0.64040506, 0.10983869]], dtype=float32), 1.8274659]\n",
            "50 [array([[0.39757478, 0.65889513, 0.11288211]], dtype=float32), 1.8530277]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}