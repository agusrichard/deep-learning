{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fodl-chapter1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DAoC-O39MSjx",
        "colab_type": "text"
      },
      "source": [
        "# Chapter 1\n",
        "# The Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7GjM9GMMvwQ",
        "colab_type": "text"
      },
      "source": [
        "- It's not quite a sufficient act if we program the computer to follow some rules made by us. So it will be much more effective if we ask the machine to find some underlying rules or pattern and learn from it.\n",
        "- When we are young, we percieve the world and making understanding, may be some understanding are certainly wrong, and we will be corrected so we knew it was wrong. Then, we update our understanding.\n",
        "- As we grow older, we always update a lot of understanding, so we more accurate and accurate at percieving information and even forecasting and predicting the future.\n",
        "- Deep learning is a subset of machine learning.\n",
        "-  In\n",
        "machine learning, instead of teaching a computer a massive list of rules to solve the\n",
        "problem, we give it a model with which it can evaluate examples, and a small set of\n",
        "instructions to modify the model when it makes a mistake."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TTJt-YxJKi1R",
        "colab_type": "text"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dp1s-9w0KkGy",
        "colab_type": "text"
      },
      "source": [
        "## The Mechanics of Machine Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PUsmXE8bEjL3",
        "colab_type": "text"
      },
      "source": [
        "Let's define ourmodel to be a function $h(x,\\theta)$. The input x is an example expressed in vector form. For example, if x were a grayscale image, the vector’s\n",
        "components would be pixel intensities at each position. Vectorizing an image will make the shape of image which usually (x\\*y\\*z) will become a vector form. The input $\\theta$ is a vector of the parameters that our model uses."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8kNIWT8KEpn2",
        "colab_type": "text"
      },
      "source": [
        "To develop a more intuitive understanding for machine learning models, let’s walk\n",
        "through a quick example. Let’s say we wanted to determine how to predict exam performance\n",
        "based on the number of hours of sleep we get and the number of hours we\n",
        "study the previous day. We collect a lot of data, and for each data point $x = [x_1 x_2]^T$,\n",
        "we record the number of hours of sleep we got ($x_1$), the number of hours we spent\n",
        "studying ($x_2$), and whether we performed above or below the class average. Our goal,\n",
        "then, might be to learn a model $h(x, \\theta)$ with parameter vector $θ = [θ_0 θ_1 θ_2]^T$ such\n",
        "that: \n",
        "\n",
        "$$ h(x, \\theta) =  \\left\\{\n",
        "\\begin{array}{ll}\n",
        "      -1 & if \\;\\;\\; x^T.\\theta + \\theta_0 < 0 \\\\\n",
        "      1 & if \\;\\;\\; x^T.\\theta + \\theta_0 \\geq 0 \\\\\n",
        "\\end{array} \n",
        "\\right. $$ "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2_0d2i0QHfBt",
        "colab_type": "text"
      },
      "source": [
        "In other words, we guess that the blueprint for our model h \ud835, θ is as described\n",
        "above (geometrically, this particular blueprint describes a linear classifier that divides\n",
        "the coordinate plane into two halves). Then, we want to learn a parameter vector\n",
        "θ such that our model makes the right predictions (−1 if we perform below average,\n",
        "and 1 otherwise) given an input example x. This model is called a linear\n",
        "perceptron, and it’s a model that’s been used since the 1950s"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RP_Ub9DoIxpJ",
        "colab_type": "text"
      },
      "source": [
        "- Usually there are not only one optimal parameters $\\theta$, in some cases there are infinitely many optimal vector parameter $\\theta$ that make the predictions correctly (with less error).\n",
        "- How can we get this optimal parameter?\n",
        "- Technique to find it is called optimization. An optimizer aims to maximize the performance of a machine learning model by iteratively tweaking its parameters untul the orror is minimized. In other words, we want to find the parameter that resulting less error, or minimizing the error.\n",
        "- Linear perceptron has disadvantages, for example it can not learn the dara with complex form or nonlinear form."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nFwFjPkXKsf4",
        "colab_type": "text"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Q-21BxcKtAc",
        "colab_type": "text"
      },
      "source": [
        "## The Neuron"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1x4yR4_VKuLc",
        "colab_type": "text"
      },
      "source": [
        "- Tiny piece of brain about the size of grain of rice, contains over 10,000 neurons, each of which forms an average of 6,00 connections with other neurons.\n",
        "- It’s the strength of each connection that determines the contribution of the input\n",
        "to the neuron’s output. After being weighted by the strength of their respective connections,\n",
        "the inputs are summed together in the cell body. This sum is then transformed\n",
        "into a new signal that’s propagated along the cell’s axon and sent off to other\n",
        "neurons. The process is inputs -> strengths -> sum/trasform -> output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ajM-NtGbLu0x",
        "colab_type": "text"
      },
      "source": [
        "Let's reformulate the inputs as a vector $x = [x_1 x_2 ... x_n]$ and weighted sum $w = [w_1 w_2 ... w_n]$. The output neuron as y = f(x.w + b), where b is the bias term"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FasVQrPs6LWc",
        "colab_type": "text"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uum70Yqb7BPY",
        "colab_type": "text"
      },
      "source": [
        "## Feed-Forward Neural Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6LZT9L027GRu",
        "colab_type": "text"
      },
      "source": [
        "- The neurons in the human brain are organized in layers. Human cerebral cortex is made up of six layers.\n",
        "- Connections only traverse from a lower layer to a higher\n",
        "layer. There are no connections between neurons in the same layer, and there are no\n",
        "connections that transmit data from a higher layer to a lower layer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46LsX6pKNBQe",
        "colab_type": "text"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQDkyrSpNCaT",
        "colab_type": "text"
      },
      "source": [
        "## Sigmoid,Tanh, and ReLU Neurons"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sd_94USkNGpf",
        "colab_type": "text"
      },
      "source": [
        "The sigmoid function:\n",
        "$f(z) = \\frac{1}{1 + e^{-z}}$\n",
        "\n",
        "\n",
        "The tanh function:\n",
        "$f(z) = tanh(z)$\n",
        "\n",
        "\n",
        "The ReLU function:\n",
        "$f(z) = max(0, z)$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmkMXst9NkzB",
        "colab_type": "text"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oln22cV0Nlkl",
        "colab_type": "text"
      },
      "source": [
        "## Softmax Output Layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YcPih0swNoFf",
        "colab_type": "text"
      },
      "source": [
        "- We want the ouput vector to be a probability distribution over a set of mutually exclusive labels.\n",
        "- The desired output vector is of the form: $[p_0 \\: p_1 \\: p_2 \\: ... \\: p_m]$ where m is the number of output neurons and $\\sum_{i=0}^{m} p_i = 1$"
      ]
    }
  ]
}