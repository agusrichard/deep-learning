{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fodl-chapter3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w6Vexnm61lgX",
        "colab_type": "text"
      },
      "source": [
        "# Chapter 3\n",
        "# Implementing Neural Networks in Tensorflow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dMvYr00i2Wv_",
        "colab_type": "text"
      },
      "source": [
        "## What is Tensorflow?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JDKZIIPe22Rp",
        "colab_type": "text"
      },
      "source": [
        "- TensorFlow is a Python library that allows users to express arbitrary\n",
        "computation as a graph of data flows.\n",
        "- Data in Tensorflow is represented as tensors, which are multidimensional arrays.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j61TMqD94Yvo",
        "colab_type": "text"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qu-5mkrb4awM",
        "colab_type": "text"
      },
      "source": [
        "## Creating and Manipulating Tensorflow Variables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MsZNYgS44fpz",
        "colab_type": "text"
      },
      "source": [
        "- We use variables to represent the parameters of the model.\n",
        "- Tensorflow variables have the follwoing three properties:\n",
        "    - Variables must be explicitly initialized before a graph is used for the first time.\n",
        "    - We can use gradient methods to modify variables after each iteration as we\n",
        "search for a model’s optimal parameter settings.\n",
        "    - We can save the values stored in variables to disk and restore them for later use."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qtGkNapw6Pf1",
        "colab_type": "text"
      },
      "source": [
        "Let’s start off by initializing a variable that\n",
        "describes the weights connecting neurons between two layers of a feed-forward neural\n",
        "network:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wy1MVFWg6h_U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2K5Rif946k-O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# weights = tf.Variable(tf.random_normal([300, 200], stddev=0.5),\n",
        "#                       name='weights')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2HIFN0b26yM1",
        "colab_type": "text"
      },
      "source": [
        "Let’s start off by initializing a variable that\n",
        "describes the weights connecting neurons between two layers of a feed-forward neural\n",
        "network:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Z-fwrG-7TWW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# weights = tf.Variable(tf.random_normal([300, 200], stddev=0.5), \n",
        "#                       name='weights', trainable=False)\n",
        "# here the weights is not meant to be trainable"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxIBwgGc7ieq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # several other methods to initialize a Tensorflow variable:\n",
        "# tf.zeros(shape, dtype=tf.float32, name=None)\n",
        "# tf.ones(shape, dtype=tf.float32m name=None)\n",
        "# tf.random_normal(shape, mean=0, stddev=1.0, dtype=tf.float32,\n",
        "#                  seed=None, name=None)\n",
        "# tf.truncated_normal(shape, mean=0, stddev=1, dtype=tf.float32,\n",
        "#                     seed=None, name=None)\n",
        "# tf.random_uniform(shape, minval=0, maxval=None, dtype=tf.float32, \n",
        "#                   seed=None, name=None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z6sl_IKF8NLw",
        "colab_type": "text"
      },
      "source": [
        "When we call tf.Variable, three operations are added to the computation graph:\n",
        "- The operation producing the tensor we use to initialize our variable.\n",
        "- The tf.assign operation, which is responsible for filling the variable with the\n",
        "initializing tensor prior to the variable’s use.\n",
        "- The variable operation, which holds the current value of the variable."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H35O_TwI9zLG",
        "colab_type": "text"
      },
      "source": [
        "As we mentioned previously in the three operations, before we use any TensorFlow\n",
        "variable, the tf.assign8 operation must be run so that the variable is appropriately\n",
        "initialized with the desired value. We can do this by running tf.initial\n",
        "ize_all_variables(),9 which will trigger all of the tf.assign operations in our\n",
        "graph. We can also selectively initialize only certain variables in our computational\n",
        "graph using the tf.initialize_variables(var1, var2, ...)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7tuGM88490B3",
        "colab_type": "text"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kY6nLTSlGNVz",
        "colab_type": "text"
      },
      "source": [
        "## TensorFlow Operations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HgvW3HuEGPVm",
        "colab_type": "text"
      },
      "source": [
        "- On a high level, TensorFlow operations represent abstract transformations\n",
        "that are applied to tensors in the computation graph.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hogPNQmEHCHM",
        "colab_type": "text"
      },
      "source": [
        "Element-wise mathematical operations: Add, Sub, Mul, Div, Exp, Log, ...\n",
        "\n",
        "Array operations: Concat, Slice, Split, Constant, ...\n",
        "\n",
        "Matrix operations: MatMul, MatrixInverse, MatrixDeterminant, ...\n",
        "\n",
        "Stateful operations: Variable, Assign, AssignAdd, ...\n",
        "\n",
        "Neural network building blocks: SoftMax, Sigmoid, ReLU, Convolutional2D, MaxPool, ...\n",
        "\n",
        "Checkpointing operations: Save, Restore, ...\n",
        "\n",
        "Queue and synchronization operations: Enqueue, Dequeue, MutexAcquaire, MutexRelease, ...\n",
        "\n",
        "Controlflow operations: Merge, Switch, Enter, Leave, NextIteration, ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KUKQFudVIKpr",
        "colab_type": "text"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8N5f8xvTIcXK",
        "colab_type": "text"
      },
      "source": [
        "## Placeholder Tensors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7VXvMeZRIfKR",
        "colab_type": "text"
      },
      "source": [
        "- The only missing piece is how we pass the input to our deep model (during\n",
        "both train and test time). A variable is insufficient because it is only meant to be initialized\n",
        "once. Instead, we need a component that we populate every single time the\n",
        "computation graph is run.\n",
        "\n",
        "A placeholder\n",
        "is instantiated as follows and can be used in operations just like ordinary TensorFlow\n",
        "variables and tensors:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ti4ey6cJDEh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# x = tf.placeholder(tf.float32, name='x', shape=[None, 784])\n",
        "# W = tf.Variable(tf.random_uniform([784, 10], -1, 1), name='W')\n",
        "# multiply = tf.matmul(x, W)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xzcr4DPBJXQS",
        "colab_type": "text"
      },
      "source": [
        "Here we define a placeholder where x represents a minibatch of data stored\n",
        "as float32’s. We notice that x has 784 columns, which means that each data sample\n",
        "has 784 dimensions. We also notice that x has an undefined number of rows. This\n",
        "means that x can be initialized with an arbitrary number of data samples. While we\n",
        "could instead multiply each data sample separately by W, expressing a full minibatch\n",
        "as a tensor allows us to compute the results for all the data samples in parallel. The\n",
        "result is that the ith row of the multiply tensor corresponds to W multiplied with\n",
        "the ith data sample."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cjdraBGlJy_1",
        "colab_type": "text"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DVNF32lxJ0Ww",
        "colab_type": "text"
      },
      "source": [
        "## Sessions in TensorFlow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LdqFiUGrJ2-7",
        "colab_type": "text"
      },
      "source": [
        "- A TensorFlow program interacts with a computation graph using a session.\n",
        "- The TensorFlow\n",
        "session is responsible for building the initial graph, and can be used to initialize\n",
        "all variables appropriately and to run the computational graph."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tOzQVaxKKItb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import tensorflow as tf\n",
        "# from read_data import get_minibatch\n",
        "\n",
        "# x = tf.placeholder(tf.float32, name='x', shape=[None, 784])\n",
        "# W = tf.Variable(tf.random_uniform([784, 10], -1, 1), name='W')\n",
        "# b = tf.Variable(tf.zeros([10]), name='biases')\n",
        "# output = tf.matmul(x, W)+ bin\n",
        "\n",
        "# init_op = tf.initializa_all_variable()\n",
        "\n",
        "# sess = tf.Session()\n",
        "# sess.run(init_op)\n",
        "# feed_dict = {'x' : get_minibatch()}\n",
        "# sess.run(output, feed_dict=feed_dict)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RSJhKYGWKwyY",
        "colab_type": "text"
      },
      "source": [
        "How exactly does a single line of code (sess.run) accomplish such a\n",
        "wide variety of functions? The answer lies in the powerful expressivity of the underlying computational graph. All of these functionalities are represented as TensorFlow\n",
        "operations that can be passed as arguments to sess.run. All sess.run needs to do is\n",
        "traverse down the computational graph to identify all of the dependencies that compose\n",
        "the relevant subgraph, ensure that all of the placeholder variables that belong to\n",
        "the identified subgraph are filled using the feed_dict, and then traverse back up the\n",
        "subgraph (executing all of the intermediate operations) to evaluate the original arguments."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ywgIgSKFMHz1",
        "colab_type": "text"
      },
      "source": [
        "In short, the sess.run scan all the dependencies along the graph and makes sure everything is good, then run the graph."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCIdj2VDMVL_",
        "colab_type": "text"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MICmO8j7MWGH",
        "colab_type": "text"
      },
      "source": [
        "## Navigating Variable Scopes and Sharing Variables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2CIwEogKMaD-",
        "colab_type": "text"
      },
      "source": [
        "Let's consider the following example:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFh_7uwNPWPN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2zac4NgOeAa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def my_network(input):\n",
        "    W_1 = tf.Variable(tf.random_uniform([784, 100], -1, 1), name=\"W_1\")\n",
        "    b_1 = tf.Variable(tf.zeros([100]), name=\"biases_1\")\n",
        "    output_1 = tf.matmul(input, W_1) + b_1\n",
        "\n",
        "    W_2 = tf.Variable(tf.random_uniform([100, 50], -1, 1), name=\"W_2\")\n",
        "    b_2 = tf.Variable(tf.zeros([50]), name=\"biases_2\")\n",
        "    output_2 = tf.matmul(output_1, W_2) + b_2\n",
        "\n",
        "    W_3 = tf.Variable(tf.random_uniform([50, 10], -1, 1), name=\"W_3\")\n",
        "    b_3 = tf.Variable(tf.zeros([10]), name=\"biases_3\")\n",
        "    output_3 = tf.matmul(output_2, W_3) + b_3\n",
        "\n",
        "    # printing names\n",
        "    print(\"Printing names of weight parameters\")\n",
        "    print(W_1.name, W_2.name, W_3.name)\n",
        "    print(\"Printing names of bias parameters\")\n",
        "    print(b_1.name, b_2.name, b_3.name)\n",
        "\n",
        "    return output_3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2hygFPrPHaj",
        "colab_type": "code",
        "outputId": "01c4955e-8b6b-4f32-a7b6-33a8eaef244e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        }
      },
      "source": [
        "i_1 = tf.placeholder(tf.float32, [1000, 784], name='i_1')\n",
        "my_network(i_1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Printing names of weight parameters\n",
            "W_1:0 W_2:0 W_3:0\n",
            "Printing names of bias parameters\n",
            "biases_1:0 biases_2:0 biases_3:0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'add_2:0' shape=(1000, 10) dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eYs2Q7waPIdw",
        "colab_type": "code",
        "outputId": "092a50ef-9abc-4cf6-8dc3-a18ed598a381",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        }
      },
      "source": [
        "i_2 = tf.placeholder(tf.float32, [1000, 784], name='i_2')\n",
        "my_network(i_2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Printing names of weight parameters\n",
            "W_1_1:0 W_2_1:0 W_3_1:0\n",
            "Printing names of bias parameters\n",
            "biases_1_1:0 biases_2_1:0 biases_3_1:0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'add_5:0' shape=(1000, 10) dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62Zp8dPiP8k0",
        "colab_type": "text"
      },
      "source": [
        "This network setup consists of six variables describing three layers. As a result, if we\n",
        "wanted to use this network multiple times, we’d prefer to encapsulate it into a compact\n",
        "function like my_network, which we can call multiple times."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aTe_ApJPP9VI",
        "colab_type": "text"
      },
      "source": [
        "If we observe closely, our second call to my_network doesn’t use the same variables as\n",
        "the first call (in fact, the names are different!). Instead, we’ve created a second set of\n",
        "variables! In many cases, we don’t want to create a copy, but rather reuse the model\n",
        "and its variables. It turns out, that in this case, we shouldn’t be using tf.Variable.\n",
        "Instead, we should be using a more advanced naming scheme that takes advantage of\n",
        "TensorFlow’s variable scoping."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ys8XbN-oQPid",
        "colab_type": "text"
      },
      "source": [
        "TensorFlow's variable scoping mechanisms are largely controlled by two functions:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWnWYDYUNavb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tf.get_variable(name, shape, initializer)\n",
        "# tf.variable_scope(scope_name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aaajwE1tNj1s",
        "colab_type": "text"
      },
      "source": [
        "Let'stry to rewrite my_network in cleaner fashion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xYHqXH3PNtGC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def layer(input, weight_shape, bias_shape):\n",
        "    weight_init = tf.random_uniform_initializer(minval=-1, maxval=1)\n",
        "    bias_init = tf.constant_initializer(value=0)\n",
        "    W = tf.get_variable(\"W\", weight_shape, initializer=weight_init)\n",
        "    b = tf.get_variable(\"b\", bias_shape, initializer=bias_init)\n",
        "\n",
        "    return tf.matmul(input, W) + b\n",
        "\n",
        "def my_network(input):\n",
        "    with tf.variable_scope(\"layer_1\"):\n",
        "        output_1 = layer(input, [784, 100], [100])\n",
        "    with tf.variable_scope(\"layer_2\"):\n",
        "        output_2 = layer(output_1, [100, 50], [50])\n",
        "    with tf.variable_scope(\"layer_3\"):\n",
        "        output_3 = layer(output_2, [50, 10], [10])\n",
        "\n",
        "    return output_3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEGQiIXhPBvJ",
        "colab_type": "code",
        "outputId": "daec3d64-0fc9-4227-a5ae-a8423c442953",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "i_1 = tf.placeholder(tf.float32, [1000, 784], name='i_1')\n",
        "my_network(i_1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'layer_3/add:0' shape=(1000, 10) dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKk8N9PkQgOq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# i_2 = tf.placeholder(tf.float32, [1000, 784], name='i_2')\n",
        "# my_network(i_2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3XZR3AhRaxL",
        "colab_type": "text"
      },
      "source": [
        "Unlike tf.Variable, the tf.get_variable command checks that a variable of the\n",
        "given name hasn’t already been instantiated. By default, sharing is not allowed (just to\n",
        "be safe!), but if we want to enable sharing within a variable scope, we can say so\n",
        "explicitly:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v0I-m8GoRkIu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# with tf.variable_scope(\"shared_variables\") as scope:\n",
        "#     i_1 = tf.placeholder(tf.float32, [1000, 784], name='i_1')\n",
        "#     my_network(i_1)\n",
        "#     scope.reuse_variables()\n",
        "#     i_2 = tf.placeholder(tf.float32, [1000, 784], name='i_2')\n",
        "#     my_network(i_2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "npT7mKmFR7K2",
        "colab_type": "text"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HvJ3GTKsSTb1",
        "colab_type": "text"
      },
      "source": [
        "## Managing Models over the CPU and GPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "07a5crvxSWnP",
        "colab_type": "text"
      },
      "source": [
        "TensorFlow allows us to utilize multiple computing devices, if we so desire, to build\n",
        "and train our models. Supported devices are represented by string IDs and normally\n",
        "consist of the following:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QZRSn-wWSc6U",
        "colab_type": "text"
      },
      "source": [
        "- \"/cpu:0\"\n",
        "The CPU of our machine.\n",
        "- \"/gpu:0\"\n",
        "The first GPU of our machine, if it has one.\n",
        "- \"/gpu:1\"\n",
        "The second GPU of our machine, if it has one."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73OYFa4ESlAt",
        "colab_type": "text"
      },
      "source": [
        "When a TensorFlow operation has both CPU and GPU kernels, and GPU use is\n",
        "enabled, TensorFlow will automatically opt to use the GPU implementation. To\n",
        "inspect which devices are used by the computational graph, we can initialize our TensorFlow\n",
        "session with the log_device_placement set to True:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tXWc0W-dSsy1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zEBaFQQrTUaC",
        "colab_type": "text"
      },
      "source": [
        "If we desire to use a specific device, we may do so by using with tf.device16 to\n",
        "select the appropriate device. If the chosen device is not available, however, an error\n",
        "will be thrown. If we would like TensorFlow to find another available device if the\n",
        "chosen device does not exist, we can pass the allow_soft_placement flag to the session\n",
        "variable as follows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1RL-M6CTTVpF",
        "colab_type": "code",
        "outputId": "7c4ffef2-e95d-43ee-8a0c-79fce6c80012",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "with tf.device('/gpu:2'):\n",
        "    a = tf.constant([1.0, 2.0, 3.0, 4.0], shape=[2, 2], name='a')\n",
        "    b = tf.constant([1.0, 2.0], shape=[2, 1], name='b')\n",
        "    c = tf.matmul(a, b)\n",
        "\n",
        "sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True,\n",
        "                                        log_device_placement=True))\n",
        "\n",
        "sess.run(c)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 5.],\n",
              "       [11.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "POiPJeIdT7P7",
        "colab_type": "text"
      },
      "source": [
        "TensorFlow also allows us to build models that span multiple GPUs by building\n",
        "models in a tower-like fashion as shown in Figure 3-3. The following code is an\n",
        "example of multi-GPU code:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wCIn4IFQUAFY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# c = []\n",
        "\n",
        "# for d in ['/gpu:0', '/gpu:0']:\n",
        "#     with tf.device(d):\n",
        "#         a = tf.constant([1.0, 2.0, 3.0, 4.0], shape=[2, 2], name='a')\n",
        "#         b = tf.constant([1.0, 2.0], shape=[2, 1], name='b')\n",
        "#         c.append(tf.matmul(a, b))\n",
        "\n",
        "# with tf.device('/cpu:0'):\n",
        "#     sum = tf.add_n(c)\n",
        "\n",
        "# sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
        "\n",
        "# sess.run(sum)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VISJ_Zw6VitN",
        "colab_type": "text"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uzUtbBnUUpZj",
        "colab_type": "text"
      },
      "source": [
        "## Specifying the Logistic Regression Model in TensorFlow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8A8k-AVsVoUg",
        "colab_type": "text"
      },
      "source": [
        "Now that we’ve developed all of the basic concepts of TensorFlow, let’s build a simple\n",
        "model to tackle the MNIST dataset. As you may recall, our goal is to identify handwritten\n",
        "digits from 28 x 28 black-and-white images. The first network that we’ll build\n",
        "implements a simple machine learning algorithm known as logistic regression."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PJNlWiheV6kR",
        "colab_type": "text"
      },
      "source": [
        "On a high level, logistic regression is a method by which we can calculate the probability\n",
        "that an input belongs to one of the target classes. In our case, we’ll compute the\n",
        "probability that a given input image is a 0, 1, ..., or 9. Our model uses a\n",
        "matrix W representing the weights of the connections in the network, as well as a\n",
        "vector b corresponding to the biases to estimate whether an input x belongs to\n",
        "class i using the softmax expression we talked about earlier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h9qXx-TWVtPx",
        "colab_type": "text"
      },
      "source": [
        "You’ll notice that the network interpretation for logistic regression is rather primitive.\n",
        "It doesn’t have any hidden layers, meaning that it is limited in its ability to learn complex\n",
        "relationships! We have an output softmax of size 10 because we have 10 possible\n",
        "outcomes for each input. Moreover, we have an input layer of size 784, one input neuron\n",
        "for every pixel in the image! As we’ll see, the model makes decent headway\n",
        "toward correctly classifying our dataset, but there’s lots of room for improvement."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sfdEni4fWO9S",
        "colab_type": "text"
      },
      "source": [
        "We’ll build the the logistic regression model in four phases:\n",
        "1. inference: produces a probability distribution over the output classes given a\n",
        "minibatch\n",
        "2. loss: computes the value of the error function (in this case, the cross-entropy\n",
        "loss)\n",
        "3. training: responsible for computing the gradients of the model’s parameters and\n",
        "updating the model\n",
        "4. evaluate: will determine the effectiveness of a model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wkZji2JgWfxq",
        "colab_type": "text"
      },
      "source": [
        "Given a minibatch, which consists of 784-dimensional vectors representing MNIST\n",
        "images, we can represent logistic regression by taking the softmax of the input multiplied\n",
        "with a matrix representing the weights connecting the input and output layer.\n",
        "Each row of the output tensor represents the probability distribution over output\n",
        "classes for each corresponding data sample in the minibatch:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ctiM0zogisb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ElYM-6VKW8Np",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def inference(x):\n",
        "    tf.constant_initializer(value=0)\n",
        "    W = tf.get_variable('W', [784, 10], initializer=init)\n",
        "    b = tf.get_variable('b', [10], initializer=init)\n",
        "    output = tf.nn.softmax(tf.matmul(x, W) + b)\n",
        "    \n",
        "    return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iKY8Ytwtgn-H",
        "colab_type": "text"
      },
      "source": [
        "Now, given the correct labels for a minibatch, we should be able to compute the average\n",
        "error per data sample. We accomplish this using the following code snippet that\n",
        "computes the cross-entropy loss over a minibatch:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bfMlNE3WguS8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loss(output, y):\n",
        "    dot_product = y * tf.log(output)\n",
        "\n",
        "    # Reduction along axis 0 collapses each column into a\n",
        "    # single value, whereas reduction along axis 1 collapses\n",
        "    # each row into a single value. In general, reduction along\n",
        "    # axis i collapses the ith dimension of a tensor to size 1.\n",
        "    xentropy = -tf.reduce_sum(dot_product, reduction_indices=1)\n",
        "\n",
        "    loss = tf.reduce_mean(xentropy)\n",
        "\n",
        "    return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5j6DYr6LhHKq",
        "colab_type": "text"
      },
      "source": [
        "Then, given the current cost incurred, we’ll want to compute the gradients and modify\n",
        "the parameters of the model appropriately. TensorFlow makes this easy by giving\n",
        "us access to built-in optimizers that produce a special train operation that we can run\n",
        "via a TensorFlow session when we minimize them. Note that when we create the\n",
        "training operation, we also pass in a variable that represents the number of minibatches\n",
        "that have been processed. Each time the training operation is run, this step\n",
        "variable is incremented so that we can keep track of progress:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YkN6NPzYhRMp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def training(cost, global_step):\n",
        "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
        "    train_op = optimizer.minimize(cost, global_step=global_step)\n",
        "    return train_op"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AhAB_OriiHwz",
        "colab_type": "text"
      },
      "source": [
        "Finally, we put together a simple computational subgraph to evaluate the model on\n",
        "the validation or test set:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UkhmG9z7i1ip",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(output, y):\n",
        "    correct_prediction= tf.equal(tf.argmax(output, 1), tf.argmax(y, 1))\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "\n",
        "    return accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "llQ3Q1LtjHjA",
        "colab_type": "text"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7enfkDQGjJYI",
        "colab_type": "text"
      },
      "source": [
        "## Logging and Training the Logistic Regression Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXYO1YPHjM5T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import input_data\n",
        "mnist.train\n",
        "\n",
        "import tensorflow as tf\n",
        "import time\n",
        "\n",
        "\n",
        "# Parameters\n",
        "learning_rate = 0.01\n",
        "training_epochs = 60\n",
        "batch_size = 100\n",
        "display_step = 1\n",
        "\n",
        "def inference(x):\n",
        "    init = tf.constant_initializer(value=0)\n",
        "    W = tf.get_variable(\"W\", [784, 10],\n",
        "                         initializer=init)\n",
        "    b = tf.get_variable(\"b\", [10],\n",
        "                         initializer=init)\n",
        "    output = tf.nn.softmax(tf.matmul(x, W) + b)\n",
        "\n",
        "    w_hist = tf.histogram_summary(\"weights\", W)\n",
        "    b_hist = tf.histogram_summary(\"biases\", b)\n",
        "    y_hist = tf.histogram_summary(\"output\", output)\n",
        "\n",
        "    return output\n",
        "\n",
        "def loss(output, y):\n",
        "    dot_product = y * tf.log(output)\n",
        "\n",
        "    # Reduction along axis 0 collapses each column into a single\n",
        "    # value, whereas reduction along axis 1 collapses each row \n",
        "    # into a single value. In general, reduction along axis i \n",
        "    # collapses the ith dimension of a tensor to size 1.\n",
        "    xentropy = -tf.reduce_sum(dot_product, reduction_indices=1)\n",
        "     \n",
        "    loss = tf.reduce_mean(xentropy)\n",
        "\n",
        "    return loss\n",
        "\n",
        "def training(cost, global_step):\n",
        "\n",
        "    tf.scalar_summary(\"cost\", cost)\n",
        "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
        "    train_op = optimizer.minimize(cost, global_step=global_step)\n",
        "\n",
        "    return train_op\n",
        "\n",
        "\n",
        "def evaluate(output, y):\n",
        "    correct_prediction = tf.equal(tf.argmax(output, 1), tf.argmax(y, 1))\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "\n",
        "    tf.scalar_summary(\"validation error\", (1.0 - accuracy))\n",
        "\n",
        "    return accuracy\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\n",
        "    with tf.Graph().as_default():\n",
        "\n",
        "        x = tf.placeholder(\"float\", [None, 784]) # mnist data image of shape 28*28=784\n",
        "        y = tf.placeholder(\"float\", [None, 10]) # 0-9 digits recognition => 10 classes\n",
        "\n",
        "\n",
        "        output = inference(x)\n",
        "\n",
        "        cost = loss(output, y)\n",
        "\n",
        "        global_step = tf.Variable(0, name='global_step', trainable=False)\n",
        "\n",
        "        train_op = training(cost, global_step)\n",
        "\n",
        "        eval_op = evaluate(output, y)\n",
        "\n",
        "        summary_op = tf.merge_all_summaries()\n",
        "\n",
        "        saver = tf.train.Saver()\n",
        "\n",
        "        sess = tf.Session()\n",
        "\n",
        "        summary_writer = tf.train.SummaryWriter(\"logistic_logs/\",\n",
        "                                            graph_def=sess.graph_def)\n",
        "\n",
        "        \n",
        "        init_op = tf.initialize_all_variables()\n",
        "\n",
        "        sess.run(init_op)\n",
        "\n",
        "\n",
        "        # Training cycle\n",
        "        for epoch in range(training_epochs):\n",
        "\n",
        "            avg_cost = 0.\n",
        "            total_batch = int(mnist.train.num_examples/batch_size)\n",
        "            # Loop over all batches\n",
        "            for i in range(total_batch):\n",
        "                minibatch_x, minibatch_y = mnist.train.next_batch(batch_size)\n",
        "                # Fit training using batch data\n",
        "                sess.run(train_op, feed_dict={x: minibatch_x, y: minibatch_y})\n",
        "                # Compute average loss\n",
        "                avg_cost += sess.run(cost, feed_dict={x: minibatch_x, y: minibatch_y})/total_batch\n",
        "            # Display logs per epoch step\n",
        "            if epoch % display_step == 0:\n",
        "                print(\"Epoch:\", '%04d' % (epoch+1), \"cost =\", \"{:.9f}\".format(avg_cost))\n",
        "\n",
        "                accuracy = sess.run(eval_op, feed_dict={x: mnist.validation.images, y: mnist.validation.labels})\n",
        "\n",
        "                print(\"Validation Error:\", (1 - accuracy))\n",
        "\n",
        "                summary_str = sess.run(summary_op, feed_dict={x: minibatch_x, y: minibatch_y})\n",
        "                summary_writer.add_summary(summary_str, sess.run(global_step))\n",
        "\n",
        "                saver.save(sess, \"logistic_logs/model-checkpoint\", global_step=global_step)\n",
        "\n",
        "\n",
        "        print(\"Optimization Finished!\")\n",
        "\n",
        "\n",
        "        accuracy = sess.run(eval_op, feed_dict={x: mnist.test.images, y: mnist.test.labels})\n",
        "\n",
        "        print(\"Test Accuracy:\", accuracy)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}